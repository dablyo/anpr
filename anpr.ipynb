{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "automated number plate recognization using vgg model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path\n",
    "import random\n",
    "import cv2\n",
    "import math\n",
    "from scipy import ndimage\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.utils.data\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torch.utils.data as data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-11-cac9aded015f>, line 6)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-11-cac9aded015f>\"\u001b[0;36m, line \u001b[0;32m6\u001b[0m\n\u001b[0;31m    nn.ReLU(inplace=True)\u001b[0m\n\u001b[0m     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "class vgg16(nn.Module):\n",
    "    def __init__(self,num_classes=1000):\n",
    "        super(vgg,self).__init__()\n",
    "        self.features=nn.Sequential(\n",
    "            nn.Conv2d(1,64,kernel_size=3,padding=1) #layer1, inputs single channel,224*224\n",
    "            nn.ReLU(inplace=True)\n",
    "            nn.Conv2d(64,64,kernel_size=3,padding=1)\n",
    "            nn.ReLU(inplace=True)\n",
    "            nn.MaxPool2d(kernel_size=2,stride=2)\n",
    "            nn.Conv2d(64,128,kernel_size=3,padding=1) #layer2 inputs 64 channel,112*112\n",
    "            nn.ReLU(inplace=True)\n",
    "            nn.Conv2d(128,128,kernel_size=3,padding=1)\n",
    "            nn.ReLU(inplace=True)\n",
    "            nn.MaxPool2d(kernel_size=2,stride=2)\n",
    "            nn.Conv2d(128,256,kernel_size=3,padding=1) #layer3 inputs 128 channel,56*56\n",
    "            nn.ReLU(inplace=True)\n",
    "            nn.Conv2d(256,256,kernel_size=3,padding=1)\n",
    "            nn.ReLU(inplace=True)\n",
    "            nn.Conv2d(256,256,kernel_size=3,padding=1)\n",
    "            nn.ReLU(inplace=True)\n",
    "            nn.MaxPool2d(kernel_size=2,stride=2)\n",
    "            nn.Conv2d(256,512,kernel_size=3,padding=1) #layer4 inputs 256 channel,28*28\n",
    "            nn.ReLU(inplace=True)\n",
    "            nn.Conv2d(512,512,kernel_size=3,padding=1)\n",
    "            nn.ReLU(inplace=True)\n",
    "            nn.Conv2d(512,512,kernel_size=3,padding=1)\n",
    "            nn.ReLU(inplace=True)\n",
    "            nn.MaxPool2d(kernel_size=2,stride=2)\n",
    "            nn.Conv2d(512,512,kernel_size=3,padding=1) #layer5 inputs 512 channel,14*14\n",
    "            nn.ReLU(inplace=True)\n",
    "            nn.Conv2d(512,512,kernel_size=3,padding=1)\n",
    "            nn.ReLU(inplace=True)\n",
    "            nn.Conv2d(512,512,kernel_size=3,padding=1)\n",
    "            nn.ReLU(inplace=True)\n",
    "            nn.MaxPool2d(kernel_size=2,stride=2)\n",
    "        )\n",
    "        self.classifier=nn.Sequential(\n",
    "            nn.Linear(512 * 7 * 7, 4096),\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096, num_classes),            \n",
    "        )\n",
    "        #self._initialize_weights\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "                if m.bias is not None:\n",
    "                    m.bias.data.zero_()\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                n = m.weight.size(1)\n",
    "                m.weight.data.normal_(0, 0.01)\n",
    "                m.bias.data.zero_()        \n",
    "        \n",
    "    def forward(self,x):\n",
    "        x=self.features(x)\n",
    "        x=x.view(x.size(0),-1)\n",
    "        x=self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class NPSET(data.Dataset):\n",
    "    picroot='np'\n",
    "\n",
    "    def __getitem__(self,index):\n",
    "        label,img=self.labels[index], self.dataset[index]\n",
    "        if self.data_transform is not None:\n",
    "            img=self.data_transform(img)\n",
    "        if self.label_transform is not None:\n",
    "            label=self.label_transform(label)\n",
    "        return label,img\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "    def __init__(self,root,data_transform=None,label_transform=None):\n",
    "        self.picroot=root\n",
    "        self.data_transform=data_transform\n",
    "        self.label_transform=label_transform\n",
    "\n",
    "\n",
    "        if not os.path.exists(self.picroot):\n",
    "            raise RuntimeError('{} doesnot exists'.format(self.picroot))\n",
    "        for root,dnames,filenames in os.walk(self.picroot):\n",
    "            imgs=np.ndarray(shape=(len(filenames),1,224,224),dtype=np.float)\n",
    "            labels=[]\n",
    "            i=0\n",
    "            for filename in filenames:\n",
    "                picfilename=os.path.join(self.picroot,filename)  #file name:\n",
    "                im=cv2.imread(picfilename,cv2.IMREAD_GRAYSCALE)\n",
    "                im=cv2.resize(im,(224,224))\n",
    "                #(thresh, im) = cv2.threshold(im, 32, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)\n",
    "                #im=cv2.erode(im,self.kernel)\n",
    "                #im=cv2.dilate(im,self.kernel)\n",
    "                #im=cv2.GaussianBlur(im,(5,5),0.1)\n",
    "                #(thresh, im) = cv2.threshold(im, 32, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)\n",
    "                imgs[i][0]=im/255\n",
    "                m=filename.split('_')  #filename stype: xxxxxxxx_xxxxxxx_x.png\n",
    "                labels.append(m[1])\n",
    "                i=i+1\n",
    "            self.dataset=imgs\n",
    "            self.labels=labels\n",
    "            self.len=len(filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'vgg16' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-f20732f4f25a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvgg16\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m#number class =?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataParallel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mcudnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbenchmark\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'vgg16' is not defined"
     ]
    }
   ],
   "source": [
    "model=vgg16()  #number class =?\n",
    "model.features=torch.nn.DataParallel(model.features)\n",
    "model.cuda()\n",
    "cudnn.benchmark=True\n",
    "batch_size=10\n",
    "transform=transforms.Compose([transforms.ToTensor(),\n",
    "                              transforms.Normalize((0.5,), (0.5,)),\n",
    "                             ])\n",
    "npset = NPSET(root='np', data_transform=transform)\n",
    "nploader = torch.utils.data.DataLoader(npset, batch_size=batch, shuffle=False, num_workers=1)  #train\n",
    "npvalset=NPSET(root='npval', data_transform=transform)\n",
    "npvalloader=torch.utils.data.DataLoader(npvalset, batch_size=batch, shuffle=False, num_workers=1) #validate\n",
    "criterion=nn.CrossEntropyLoss().cuda()\n",
    "optimizer=torch.optim.SGD(model.parameters,0.1,momentum=0.9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the precision@k for the specified values of k\"\"\"\n",
    "    maxk = max(topk)\n",
    "    batch_size = target.size(0)\n",
    "\n",
    "    _, pred = output.topk(maxk, 1, True, True)\n",
    "    pred = pred.t()\n",
    "    correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "    res = []\n",
    "    for k in topk:\n",
    "        correct_k = correct[:k].view(-1).float().sum(0)\n",
    "        res.append(correct_k.mul_(100.0 / batch_size))\n",
    "    return res\n",
    "\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "        \n",
    "losses = AverageMeter()\n",
    "top1 = AverageMeter()\n",
    "top5 = AverageMeter()        \n",
    "for epoch in range(0,1):\n",
    "    #Sets the learning rate to the initial LR decayed by 10 every 30 epochs\n",
    "    lr=0.1*(0.1**(epoch//30))\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr']=lr\n",
    "    #train\n",
    "    model.train()\n",
    "    for i,data in enumerate(nploader):\n",
    "        inputs,target = data\n",
    "        #target=target.cuda()\n",
    "        input_var=torch.autograd.Variable(inputs)\n",
    "        target_var=torch.autograd.Variable(target)\n",
    "        output=model(input_var)\n",
    "        loss=criterion(output,target_var)\n",
    "        # measure accuracy and record loss\n",
    "        prec1, prec5 = accuracy(output.data, target, topk=(1, 5))\n",
    "        losses.update(loss.data[0], input.size(0))\n",
    "        top1.update(prec1[0], input.size(0))\n",
    "        top5.update(prec5[0], input.size(0))\n",
    "        # compute gradient and do SGD step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        #\n",
    "        if i% 10 == 0:\n",
    "            print('Eoch: [{0}][{1}/{2}]\\t'\n",
    "                  'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
    "                  'Prec@1 {top1.val:.3f} ({top1.avg:.3f})\\t'\n",
    "                  'Prec@5 {top5.val:.3f} ({top5.avg:.3f})').format(i,len(nploader),loss=losses,top1=top1,top5=top5)\n",
    "        \n",
    "    #validate\n",
    "    model.eval()\n",
    "    for i, data in enumerate(npvalloader):\n",
    "        (inputs, target)=data\n",
    "        #target = target.cuda()\n",
    "        input_var = torch.autograd.Variable(inputs, volatile=True)\n",
    "        target_var = torch.autograd.Variable(target, volatile=True)\n",
    "        # compute output\n",
    "        output = model(input_var)\n",
    "        loss = criterion(output, target_var)\n",
    "        # measure accuracy and record loss\n",
    "        prec1, prec5 = accuracy(output.data, target, topk=(1, 5))\n",
    "        losses.update(loss.data[0], inputs.size(0))\n",
    "        top1.update(prec1[0], inputs.size(0))\n",
    "        top5.update(prec5[0], inputs.size(0))\n",
    "        #\n",
    "        if i % 10 == 0:\n",
    "            print('Test: [{0}/{1}]\\t'\n",
    "                  'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
    "                  'Prec@1 {top1.val:.3f} ({top1.avg:.3f})\\t'\n",
    "                  'Prec@5 {top5.val:.3f} ({top5.avg:.3f})'.format(\n",
    "                   i, len(npvalloader), loss=losses,\n",
    "                   top1=top1, top5=top5))\n",
    "        prec1=top1.avg\n",
    "        # remember best prec@1 and save checkpoint\n",
    "        is_best = prec1 > best_prec1\n",
    "        best_prec1 = max(prec1, best_prec1)\n",
    "    if is_best:\n",
    "        torch.save({\n",
    "            'epoch': epoch + 1,\n",
    "            'arch:vgg16',\n",
    "            'state_dict': model.state_dict(),\n",
    "            'best_prec1': best_prec1,\n",
    "        })"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
