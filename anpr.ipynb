{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "多标签车牌识别"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "一些参考:\n",
    "https://discuss.pytorch.org/t/multi-label-classification-in-pytorch/905/16\n",
    "Multi Label Classification in pytorch\n",
    "\n",
    "https://discuss.pytorch.org/t/calculating-accuracy-for-a-multi-label-classification-problem/2303\n",
    "Calculating accuracy for a multi-label classification problem\n",
    "\n",
    "https://discuss.pytorch.org/t/equivalent-of-tensorflows-sigmoid-cross-entropy-with-logits-in-pytorch/1985\n",
    "Equivalent of TensorFlow’s Sigmoid Cross Entropy With Logits in Pytorch\n",
    "\n",
    "https://www.kaggle.com/mratsim/starting-kit-for-pytorch-deep-learning\n",
    "Starting Kit for PyTorch Deep Learning\n",
    "\n",
    "http://stackoverflow.com/questions/34240703/difference-between-tensorflow-tf-nn-softmax-and-tf-nn-softmax-cross-entropy-with\n",
    "difference between tensorflow tf.nn.softmax and tf.nn.softmax_cross_entropy_with_logits\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path\n",
    "import random\n",
    "import cv2\n",
    "import math\n",
    "from scipy import ndimage\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torch.utils.data as torch_utils_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DIGITS = \"0123456789\"\n",
    "LETTERS = \"ABCDEFGHIJKLMNOPQRSTUVWXYZ\"\n",
    "#PROVINCE=\"黑吉辽京津内冀鲁豫徽苏沪浙赣闽粤鄂湘云贵川渝藏青宁新陕甘宁晋\" #30\n",
    "CHARS = LETTERS + DIGITS\n",
    "NPLEN=7\n",
    "NUM_CLASSES=len(CHARS)*NPLEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class anprmodel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(anprmodel,self).__init__()\n",
    "        self.num_classes=NUM_CLASSES\n",
    "        self.conv1=nn.Conv2d(1,48,kernel_size=5,padding=2)\n",
    "        self.pool1=nn.MaxPool2d(kernel_size=2,stride=2)\n",
    "        self.conv2=nn.Conv2d(48,64,kernel_size=5,padding=2)\n",
    "        self.pool2=nn.MaxPool2d(kernel_size=(2,1),stride=(2,1)) \n",
    "        self.conv3=nn.Conv2d(64,128,kernel_size=5,padding=2)\n",
    "        self.pool3=nn.MaxPool2d(kernel_size=(2,2),stride=(2,2))        \n",
    "        self.fc1=nn.Linear(32*8*128,2048)\n",
    "        self.fc2=nn.Linear(2048,NUM_CLASSES)\n",
    "\n",
    "    def forward(self,x): \n",
    "        x=F.relu(self.pool1(self.conv1(x)))  #128*64\n",
    "        x=F.relu(self.pool2(self.conv2(x)))  #64*32\n",
    "        x=F.relu(self.pool3(self.conv3(x)))  #64*16\n",
    "        x=x.view(-1,32*8*128)                        #32*8\n",
    "        x=F.relu(self.fc1(x))\n",
    "        x=self.fc2(x)                                       \n",
    "        #return x\n",
    "        return F.sigmoid(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class NPSET(torch_utils_data.Dataset):\n",
    "    picroot='np'\n",
    "   \n",
    "    def code_to_vec(self,code):  #(self,p, code):\n",
    "        def char_to_vec(c):\n",
    "            y = np.zeros((len(CHARS),),dtype=np.float)   #multilabel soft margin loss\n",
    "            #y = np.zeros((len(CHARS),),dtype=np.long)   #multilabel margin loss\n",
    "            y[CHARS.index(c)] = 1.0\n",
    "            return y\n",
    "        c = np.vstack([char_to_vec(c) for c in code])\n",
    "        return c.flatten()\n",
    "        #return np.concatenate([[1. if p else 0], c.flatten()])\n",
    "\n",
    "    def __getitem__(self,index):\n",
    "        label=self.labels[index]\n",
    "        im=cv2.imread(self.dataset[index],cv2.IMREAD_GRAYSCALE)\n",
    "        img=np.reshape(im,(1,im.shape[0],im.shape[1]))\n",
    "        if self.data_transform is not None:\n",
    "            img=self.data_transform(img)\n",
    "        labelarray=self.code_to_vec(label)\n",
    "        return img,torch.FloatTensor(labelarray)\n",
    "        #return img,torch.LongTensor(labelarray)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "    def __init__(self,root,data_transform=None):\n",
    "        self.picroot=root\n",
    "        self.data_transform=data_transform\n",
    "        self.labels=[]\n",
    "        self.dataset=[]\n",
    "        if not os.path.exists(self.picroot):\n",
    "            raise RuntimeError('{} doesnot exists'.format(self.picroot))\n",
    "        for root,dnames,filenames in os.walk(self.picroot):\n",
    "            for filename in filenames:\n",
    "                picfilename=os.path.join(self.picroot,filename)  #file name:\n",
    "                m=filename.split('_')  #filename style: xxxxxxxx_xxxxxxx_x.png\n",
    "                self.labels.append(m[1])\n",
    "                self.dataset.append(picfilename)\n",
    "            self.len=len(filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#104.149524851 3266.80839036\n",
    "model=anprmodel()\n",
    "#model.features=torch.nn.DataParallel(model.features)\n",
    "#model.cuda()\n",
    "cudnn.benchmark=True\n",
    "batch_size=5\n",
    "data_transform=transforms.Compose([transforms.ToTensor(),\n",
    "                                   #transforms.RandomHorizontalFlip(),\n",
    "                                   transforms.Normalize((104.149524851,), (3266.80839036,)),\n",
    "                             ])\n",
    "npset = NPSET(root='/home/wang/git/nppic/su_np-128x64/train', data_transform=data_transform)\n",
    "nploader = torch.utils.data.DataLoader(npset, batch_size=batch_size, shuffle=True, num_workers=1)  #train\n",
    "criterion=nn.MultiLabelSoftMarginLoss()  #MultiLabelMarginLoss()\n",
    "#criterion=F.binary_cross_entropy()\n",
    "optimizer=torch.optim.SGD(model.parameters(),0.001,momentum=0.9)\n",
    "#optimizer=torch.optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "npvalset=NPSET(root='/home/wang/git/nppic/su_np-128x64/val', data_transform=data_transform)\n",
    "npvalloader=torch.utils.data.DataLoader(npvalset, batch_size=10, shuffle=False, num_workers=1) #validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [38/500 (19%)]\\tLoss: 0.692813\n",
      "Train Epoch: 0 [78/500 (39%)]\\tLoss: 0.692181\n",
      "Train Epoch: 0 [118/500 (59%)]\\tLoss: 0.691722\n",
      "Train Epoch: 0 [158/500 (79%)]\\tLoss: 0.691328\n",
      "Train Epoch: 0 [198/500 (99%)]\\tLoss: 0.690720\n",
      "Train Epoch: 1 [38/500 (19%)]\\tLoss: 0.689959\n",
      "Train Epoch: 1 [78/500 (39%)]\\tLoss: 0.689285\n",
      "Train Epoch: 1 [118/500 (59%)]\\tLoss: 0.688647\n",
      "Train Epoch: 1 [158/500 (79%)]\\tLoss: 0.687790\n",
      "Train Epoch: 1 [198/500 (99%)]\\tLoss: 0.687011\n",
      "Train Epoch: 2 [38/500 (19%)]\\tLoss: 0.685873\n",
      "Train Epoch: 2 [78/500 (39%)]\\tLoss: 0.684709\n",
      "Train Epoch: 2 [118/500 (59%)]\\tLoss: 0.683183\n",
      "Train Epoch: 2 [158/500 (79%)]\\tLoss: 0.681328\n",
      "Train Epoch: 2 [198/500 (99%)]\\tLoss: 0.678924\n",
      "Train Epoch: 3 [38/500 (19%)]\\tLoss: 0.675632\n",
      "Train Epoch: 3 [78/500 (39%)]\\tLoss: 0.671177\n",
      "Train Epoch: 3 [118/500 (59%)]\\tLoss: 0.665022\n",
      "Train Epoch: 3 [158/500 (79%)]\\tLoss: 0.655608\n",
      "Train Epoch: 3 [198/500 (99%)]\\tLoss: 0.639786\n",
      "Train Epoch: 4 [38/500 (19%)]\\tLoss: 0.612946\n",
      "Train Epoch: 4 [78/500 (39%)]\\tLoss: 0.561325\n",
      "Train Epoch: 4 [118/500 (59%)]\\tLoss: 0.459989\n",
      "Train Epoch: 4 [158/500 (79%)]\\tLoss: 0.285839\n",
      "Train Epoch: 4 [198/500 (99%)]\\tLoss: 0.137912\n",
      "Train Epoch: 5 [38/500 (19%)]\\tLoss: 0.100321\n",
      "Train Epoch: 5 [78/500 (39%)]\\tLoss: 0.091587\n",
      "Train Epoch: 5 [118/500 (59%)]\\tLoss: 0.094346\n",
      "Train Epoch: 5 [158/500 (79%)]\\tLoss: 0.088508\n",
      "Train Epoch: 5 [198/500 (99%)]\\tLoss: 0.086885\n",
      "Train Epoch: 6 [38/500 (19%)]\\tLoss: 0.083859\n",
      "Train Epoch: 6 [78/500 (39%)]\\tLoss: 0.085430\n",
      "Train Epoch: 6 [118/500 (59%)]\\tLoss: 0.083535\n",
      "Train Epoch: 6 [158/500 (79%)]\\tLoss: 0.091566\n",
      "Train Epoch: 6 [198/500 (99%)]\\tLoss: 0.083105\n",
      "Train Epoch: 7 [38/500 (19%)]\\tLoss: 0.085177\n",
      "Train Epoch: 7 [78/500 (39%)]\\tLoss: 0.083642\n",
      "Train Epoch: 7 [118/500 (59%)]\\tLoss: 0.081535\n",
      "Train Epoch: 7 [158/500 (79%)]\\tLoss: 0.081744\n",
      "Train Epoch: 7 [198/500 (99%)]\\tLoss: 0.084073\n",
      "Train Epoch: 8 [38/500 (19%)]\\tLoss: 0.081167\n",
      "Train Epoch: 8 [78/500 (39%)]\\tLoss: 0.081281\n",
      "Train Epoch: 8 [118/500 (59%)]\\tLoss: 0.084006\n",
      "Train Epoch: 8 [158/500 (79%)]\\tLoss: 0.084090\n",
      "Train Epoch: 8 [198/500 (99%)]\\tLoss: 0.083707\n",
      "Train Epoch: 9 [38/500 (19%)]\\tLoss: 0.083331\n",
      "Train Epoch: 9 [78/500 (39%)]\\tLoss: 0.084305\n",
      "Train Epoch: 9 [118/500 (59%)]\\tLoss: 0.081805\n",
      "Train Epoch: 9 [158/500 (79%)]\\tLoss: 0.083138\n",
      "Train Epoch: 9 [198/500 (99%)]\\tLoss: 0.088336\n",
      "Train Epoch: 10 [38/500 (19%)]\\tLoss: 0.082506\n",
      "Train Epoch: 10 [78/500 (39%)]\\tLoss: 0.079988\n",
      "Train Epoch: 10 [118/500 (59%)]\\tLoss: 0.084405\n",
      "Train Epoch: 10 [158/500 (79%)]\\tLoss: 0.080893\n",
      "Train Epoch: 10 [198/500 (99%)]\\tLoss: 0.085901\n",
      "Train Epoch: 11 [38/500 (19%)]\\tLoss: 0.086212\n",
      "Train Epoch: 11 [78/500 (39%)]\\tLoss: 0.084520\n",
      "Train Epoch: 11 [118/500 (59%)]\\tLoss: 0.086360\n",
      "Train Epoch: 11 [158/500 (79%)]\\tLoss: 0.081753\n",
      "Train Epoch: 11 [198/500 (99%)]\\tLoss: 0.081856\n",
      "Train Epoch: 12 [38/500 (19%)]\\tLoss: 0.082495\n",
      "Train Epoch: 12 [78/500 (39%)]\\tLoss: 0.087837\n",
      "Train Epoch: 12 [118/500 (59%)]\\tLoss: 0.082865\n",
      "Train Epoch: 12 [158/500 (79%)]\\tLoss: 0.084118\n",
      "Train Epoch: 12 [198/500 (99%)]\\tLoss: 0.084365\n",
      "Train Epoch: 13 [38/500 (19%)]\\tLoss: 0.089290\n",
      "Train Epoch: 13 [78/500 (39%)]\\tLoss: 0.081237\n",
      "Train Epoch: 13 [118/500 (59%)]\\tLoss: 0.084483\n",
      "Train Epoch: 13 [158/500 (79%)]\\tLoss: 0.082747\n",
      "Train Epoch: 13 [198/500 (99%)]\\tLoss: 0.083614\n",
      "Train Epoch: 14 [38/500 (19%)]\\tLoss: 0.081610\n",
      "Train Epoch: 14 [78/500 (39%)]\\tLoss: 0.091301\n",
      "Train Epoch: 14 [118/500 (59%)]\\tLoss: 0.079242\n",
      "Train Epoch: 14 [158/500 (79%)]\\tLoss: 0.081716\n",
      "Train Epoch: 14 [198/500 (99%)]\\tLoss: 0.084922\n",
      "Train Epoch: 15 [38/500 (19%)]\\tLoss: 0.082708\n",
      "Train Epoch: 15 [78/500 (39%)]\\tLoss: 0.081687\n",
      "Train Epoch: 15 [118/500 (59%)]\\tLoss: 0.083692\n",
      "Train Epoch: 15 [158/500 (79%)]\\tLoss: 0.088696\n",
      "Train Epoch: 15 [198/500 (99%)]\\tLoss: 0.084474\n",
      "Train Epoch: 16 [38/500 (19%)]\\tLoss: 0.080873\n",
      "Train Epoch: 16 [78/500 (39%)]\\tLoss: 0.083804\n",
      "Train Epoch: 16 [118/500 (59%)]\\tLoss: 0.080986\n",
      "Train Epoch: 16 [158/500 (79%)]\\tLoss: 0.083340\n",
      "Train Epoch: 16 [198/500 (99%)]\\tLoss: 0.082821\n",
      "Train Epoch: 17 [38/500 (19%)]\\tLoss: 0.087032\n",
      "Train Epoch: 17 [78/500 (39%)]\\tLoss: 0.081636\n",
      "Train Epoch: 17 [118/500 (59%)]\\tLoss: 0.082049\n",
      "Train Epoch: 17 [158/500 (79%)]\\tLoss: 0.083437\n",
      "Train Epoch: 17 [198/500 (99%)]\\tLoss: 0.079320\n",
      "Train Epoch: 18 [38/500 (19%)]\\tLoss: 0.082544\n",
      "Train Epoch: 18 [78/500 (39%)]\\tLoss: 0.082259\n",
      "Train Epoch: 18 [118/500 (59%)]\\tLoss: 0.084959\n",
      "Train Epoch: 18 [158/500 (79%)]\\tLoss: 0.080751\n",
      "Train Epoch: 18 [198/500 (99%)]\\tLoss: 0.082014\n",
      "Train Epoch: 19 [38/500 (19%)]\\tLoss: 0.083053\n",
      "Train Epoch: 19 [78/500 (39%)]\\tLoss: 0.085070\n",
      "Train Epoch: 19 [118/500 (59%)]\\tLoss: 0.080003\n",
      "Train Epoch: 19 [158/500 (79%)]\\tLoss: 0.080240\n",
      "Train Epoch: 19 [198/500 (99%)]\\tLoss: 0.084083\n",
      "Train Epoch: 20 [38/500 (19%)]\\tLoss: 0.080382\n",
      "Train Epoch: 20 [78/500 (39%)]\\tLoss: 0.089524\n",
      "Train Epoch: 20 [118/500 (59%)]\\tLoss: 0.082728\n",
      "Train Epoch: 20 [158/500 (79%)]\\tLoss: 0.083858\n",
      "Train Epoch: 20 [198/500 (99%)]\\tLoss: 0.084102\n",
      "Train Epoch: 21 [38/500 (19%)]\\tLoss: 0.080741\n",
      "Train Epoch: 21 [78/500 (39%)]\\tLoss: 0.089013\n",
      "Train Epoch: 21 [118/500 (59%)]\\tLoss: 0.082152\n",
      "Train Epoch: 21 [158/500 (79%)]\\tLoss: 0.083942\n",
      "Train Epoch: 21 [198/500 (99%)]\\tLoss: 0.081079\n",
      "Train Epoch: 22 [38/500 (19%)]\\tLoss: 0.081989\n",
      "Train Epoch: 22 [78/500 (39%)]\\tLoss: 0.083257\n",
      "Train Epoch: 22 [118/500 (59%)]\\tLoss: 0.085861\n",
      "Train Epoch: 22 [158/500 (79%)]\\tLoss: 0.081371\n",
      "Train Epoch: 22 [198/500 (99%)]\\tLoss: 0.084484\n",
      "Train Epoch: 23 [38/500 (19%)]\\tLoss: 0.081150\n",
      "Train Epoch: 23 [78/500 (39%)]\\tLoss: 0.078361\n",
      "Train Epoch: 23 [118/500 (59%)]\\tLoss: 0.084571\n",
      "Train Epoch: 23 [158/500 (79%)]\\tLoss: 0.090763\n",
      "Train Epoch: 23 [198/500 (99%)]\\tLoss: 0.083315\n",
      "Train Epoch: 24 [38/500 (19%)]\\tLoss: 0.080748\n",
      "Train Epoch: 24 [78/500 (39%)]\\tLoss: 0.088555\n",
      "Train Epoch: 24 [118/500 (59%)]\\tLoss: 0.084496\n",
      "Train Epoch: 24 [158/500 (79%)]\\tLoss: 0.081225\n",
      "Train Epoch: 24 [198/500 (99%)]\\tLoss: 0.087743\n",
      "Train Epoch: 25 [38/500 (19%)]\\tLoss: 0.081386\n",
      "Train Epoch: 25 [78/500 (39%)]\\tLoss: 0.083048\n",
      "Train Epoch: 25 [118/500 (59%)]\\tLoss: 0.082704\n",
      "Train Epoch: 25 [158/500 (79%)]\\tLoss: 0.081372\n",
      "Train Epoch: 25 [198/500 (99%)]\\tLoss: 0.081328\n",
      "Train Epoch: 26 [38/500 (19%)]\\tLoss: 0.078760\n",
      "Train Epoch: 26 [78/500 (39%)]\\tLoss: 0.084837\n",
      "Train Epoch: 26 [118/500 (59%)]\\tLoss: 0.084063\n",
      "Train Epoch: 26 [158/500 (79%)]\\tLoss: 0.085214\n",
      "Train Epoch: 26 [198/500 (99%)]\\tLoss: 0.090732\n",
      "Train Epoch: 27 [38/500 (19%)]\\tLoss: 0.082468\n",
      "Train Epoch: 27 [78/500 (39%)]\\tLoss: 0.081984\n",
      "Train Epoch: 27 [118/500 (59%)]\\tLoss: 0.086180\n",
      "Train Epoch: 27 [158/500 (79%)]\\tLoss: 0.084497\n",
      "Train Epoch: 27 [198/500 (99%)]\\tLoss: 0.081809\n",
      "Train Epoch: 28 [38/500 (19%)]\\tLoss: 0.082567\n",
      "Train Epoch: 28 [78/500 (39%)]\\tLoss: 0.082175\n",
      "Train Epoch: 28 [118/500 (59%)]\\tLoss: 0.081873\n",
      "Train Epoch: 28 [158/500 (79%)]\\tLoss: 0.081523\n",
      "Train Epoch: 28 [198/500 (99%)]\\tLoss: 0.084015\n",
      "Train Epoch: 29 [38/500 (19%)]\\tLoss: 0.081794\n",
      "Train Epoch: 29 [78/500 (39%)]\\tLoss: 0.080127\n",
      "Train Epoch: 29 [118/500 (59%)]\\tLoss: 0.083426\n",
      "Train Epoch: 29 [158/500 (79%)]\\tLoss: 0.086233\n",
      "Train Epoch: 29 [198/500 (99%)]\\tLoss: 0.082037\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(0,30):\n",
    "    #Sets the learning rate to the initial LR decayed by 10 every 30 epochs\n",
    "    #lr=0.1*(0.1**(epoch//30))\n",
    "    #for param_group in optimizer.param_groups:\n",
    "    #    param_group['lr']=lr\n",
    "    #train\n",
    "    model.train()\n",
    "    for i,data in enumerate(nploader):\n",
    "        inputs,targets = data\n",
    "        input_var=torch.autograd.Variable(inputs)\n",
    "        target_var=torch.autograd.Variable(targets)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output=model(input_var)\n",
    "        #porcess loss\n",
    "        #loss=criterion(output,target_var)\n",
    "        loss = F.binary_cross_entropy(output, target_var)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        #\n",
    "        if (i+1)% 20 == 0:\n",
    "             print('Train Epoch: {} [{}/{} ({:.0f}%)]\\\\tLoss: {:.6f}'.format(\n",
    "                  epoch, i * len(data), len(nploader.dataset),\n",
    "                  100. * i / len(nploader), loss.data[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 252])\n",
      "\n",
      "\n",
      "Columns 0 to 12 \n",
      "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "    1     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0     0     0     1\n",
      "    0     0     0     0     0     0     0     0     0     0     0     0     1\n",
      "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "\n",
      "Columns 13 to 25 \n",
      "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "\n",
      "Columns 26 to 35 \n",
      "    1     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0\n",
      "    1     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     0     0     0     0\n",
      "    0     0     0     0     0     0     1     0     0     0\n",
      "    0     0     0     0     0     0     0     1     0     0\n",
      "[torch.FloatTensor of size 7x36]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print targets.size()\n",
    "t=torch.Tensor(targets.size())\n",
    "t.copy_(targets)\n",
    "targetre=t.resize_(5,7,36)\n",
    "print targetre[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "npvaliter=iter(npvalloader)\n",
    "inputs,targets=npvaliter.next()\n",
    "input_var = torch.autograd.Variable(inputs, volatile=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output = model(input_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 0.0006  0.0006  0.0006  ...   0.0891  0.0742  0.1139\n",
      " 0.0006  0.0006  0.0006  ...   0.0891  0.0742  0.1139\n",
      " 0.0006  0.0006  0.0006  ...   0.0891  0.0742  0.1139\n",
      "          ...             ⋱             ...          \n",
      " 0.0006  0.0006  0.0006  ...   0.0891  0.0742  0.1139\n",
      " 0.0006  0.0006  0.0006  ...   0.0891  0.0742  0.1139\n",
      " 0.0006  0.0006  0.0006  ...   0.0891  0.0742  0.1139\n",
      "[torch.FloatTensor of size 10x252]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#type(output)\n",
    "#o=torch.sigmoid(output).data\n",
    "print output.data\n",
    "#print o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251], [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251], [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251], [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251], [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251], [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251], [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251], [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251], [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251], [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251]]\n"
     ]
    }
   ],
   "source": [
    "recs=[]\n",
    "for _,r in enumerate(o):\n",
    "    rec=[]\n",
    "    for i,re in enumerate(r):\n",
    "        if re>0.5:\n",
    "            rec.append(i)\n",
    "    recs.append(rec)        \n",
    "print recs\n",
    "\n",
    "#print output.size()\n",
    "#print output\n",
    "#print targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "o=torch.sigmoid(output).data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "outputdata=output.data\n",
    "t=torch.Tensor(outputdata.size())\n",
    "t.copy_(outputdata)\n",
    "outputre=t.resize_(4,7,36)\n",
    "t.copy_(targets)\n",
    "targetre=t.resize_(4,7,36)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print outputdata.size()\n",
    "print outputre.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "_,predicted = torch.max(outputre, 2)\n",
    "print predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print len(nploader) \n",
    "print len(inputs)\n",
    "print len(nploader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    #validate\n",
    "    model.eval()\n",
    "    for i, data in enumerate(npvalloader):\n",
    "        (inputs, target)=data\n",
    "        #target = target.cuda()\n",
    "        input_var = torch.autograd.Variable(inputs, volatile=True)\n",
    "        target_var = torch.autograd.Variable(target, volatile=True)\n",
    "        # compute output\n",
    "        output = model(input_var)\n",
    "        #porcess loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#将su_np-256x128,541张仅车牌的灰度图像，调整大小输出到su_np-128x64中\n",
    "SOURCE='/home/wang/git/nppic/su_np-256x128'\n",
    "DEST='/home/wang/git/nppic/su_np-128x64'\n",
    "for parent,dirnames,filenames in os.walk(SOURCE):\n",
    "    for fname in filenames:\n",
    "        im=cv2.imread(os.path.join(parent,fname))\n",
    "        imr=cv2.resize(im,(128,64))\n",
    "        img=cv2.cvtColor(imr,cv2.COLOR_BGR2GRAY)\n",
    "        #cv2.imwrite(os.path.join(DEST,fname),img)\n",
    "print 'over'        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#计算SOURCE目录下图片的均值和方差\n",
    "SOURCE='/home/wang/git/nppic/su_np-128x64'\n",
    "f=[]\n",
    "for parent,dirnames,filenames in os.walk(SOURCE):\n",
    "     for i,fname in enumerate(filenames):\n",
    "        f.append(os.path.join(parent,fname))\n",
    "img=np.ndarray((len(f),64,128))\n",
    "for i,fname in enumerate(f):\n",
    "    im=cv2.imread(fname)\n",
    "    img[i]=cv2.cvtColor(im,cv2.COLOR_BGR2GRAY)\n",
    "mean=np.mean(img)\n",
    "var=np.var(img)\n",
    "print mean,var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def code_to_vec(p, code):\n",
    "    def char_to_vec(c):\n",
    "        y = np.zeros((len(CHARS),))\n",
    "        y[CHARS.index(c)] = 1.0\n",
    "        return y\n",
    "    c = np.vstack([char_to_vec(c) for c in code])\n",
    "    return c,c.flatten()\n",
    "a,b=code_to_vec('1','0AV253C')\n",
    "print 'NUMCLASSES={}'.format(NUM_CLASSES)\n",
    "print a.shape,a\n",
    "print '-----------------'\n",
    "print b.shape,b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#multi label classification example\n",
    "#---------------------------------------------------------------------------------------------\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "from  torch.autograd import Variable\n",
    "\n",
    "train=[]\n",
    "labels=[]\n",
    "for i in range(10000):\n",
    "    category=(np.random.choice([0,1]),np.random.choice([0,1]))\n",
    "    if category==(1,0):\n",
    "        train.append([np.random.uniform(0.1,1),0])\n",
    "        labels.append([1,0,1])\n",
    "    if category==(0,1):\n",
    "        train.append([0,np.random.uniform(0.1,1)])\n",
    "        labels.append([0,1,0])\n",
    "    if category==(0,0):\n",
    "        train.append([np.random.uniform(0.1,1),np.random.uniform(0.1,1)])\n",
    "        labels.append([0,0,1])\n",
    "        \n",
    "class _classifier(nn.Module):\n",
    "    def __init__(self,nlabel):\n",
    "        super(_classifier,self).__init__()\n",
    "        self.main=nn.Sequential(\n",
    "            nn.Linear(2,64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64,nlabel),\n",
    "        )\n",
    "    def forward(self,input):\n",
    "        return self.main(input)\n",
    "    \n",
    "nlabel=len(labels[0])    \n",
    "classifier=_classifier(nlabel)\n",
    "optimizer=optim.Adam(classifier.parameters())\n",
    "criterion=nn.MultiLabelSoftMarginLoss()\n",
    "\n",
    "epochs=1\n",
    "for epoch in range(epochs):\n",
    "    losses=[]\n",
    "    for i,sample in enumerate(train):\n",
    "        inputv=Variable(torch.FloatTensor(sample)).view(1,-1)\n",
    "        labelsv=Variable(torch.FloatTensor(labels[i])).view(1,-1)\n",
    "        output=classifier(inputv)\n",
    "        loss=criterion(output,labelsv)\n",
    "        print loss\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/mratsim/starting-kit-for-pytorch-deep-learning\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "from torch import np # Torch wrapper for Numpy\n",
    "\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "IMG_PATH = '../input/train-jpg/'\n",
    "IMG_EXT = '.jpg'\n",
    "TRAIN_DATA = '../input/train.csv'\n",
    "\n",
    "class KaggleAmazonDataset(Dataset):\n",
    "    \"\"\"Dataset wrapping images and target labels for Kaggle - Planet Amazon from Space competition.\n",
    "\n",
    "    Arguments:\n",
    "        A CSV file path\n",
    "        Path to image folder\n",
    "        Extension of images\n",
    "        PIL transforms\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, csv_path, img_path, img_ext, transform=None):\n",
    "    \n",
    "        tmp_df = pd.read_csv(csv_path)\n",
    "        assert tmp_df['image_name'].apply(lambda x: os.path.isfile(img_path + x + img_ext)).all(), \\\n",
    "\"Some images referenced in the CSV file were not found\"\n",
    "        \n",
    "        self.mlb = MultiLabelBinarizer()\n",
    "        self.img_path = img_path\n",
    "        self.img_ext = img_ext\n",
    "        self.transform = transform\n",
    "\n",
    "        self.X_train = tmp_df['image_name']\n",
    "        self.y_train = self.mlb.fit_transform(tmp_df['tags'].str.split()).astype(np.float32)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img = Image.open(self.img_path + self.X_train[index] + self.img_ext)\n",
    "        img = img.convert('RGB')\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        \n",
    "        label = torch.from_numpy(self.y_train[index])\n",
    "        return img, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X_train.index)\n",
    "        \n",
    "transformations = transforms.Compose([transforms.Scale(32),transforms.ToTensor()])\n",
    "\n",
    "dset_train = KaggleAmazonDataset(TRAIN_DATA,IMG_PATH,IMG_EXT,transformations)\n",
    "        \n",
    "\n",
    "\n",
    "train_loader = DataLoader(dset_train,\n",
    "                          batch_size=256,\n",
    "                          shuffle=True,\n",
    "                          num_workers=4 # 1 for CUDA\n",
    "                         # pin_memory=True # CUDA only\n",
    "                         )\n",
    "\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(2304, 256)\n",
    "        self.fc2 = nn.Linear(256, 17)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(x.size(0), -1) # Flatten layer\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return F.sigmoid(x)\n",
    "\n",
    "model = Net() # On CPU\n",
    "#model = Net().cuda() # On GPU\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.5)\n",
    "\n",
    "\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        # data, target = data.cuda(async=True), target.cuda(async=True) # On GPU\n",
    "        data, target = Variable(data), Variable(target)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.binary_cross_entropy(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 10 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.data[0]))\n",
    "\n",
    "for epoch in range(1, 2):\n",
    "    train(epoch)\n",
    "    \n",
    "\n",
    "\n",
    "Train Epoch: 1 [0/40479 (0%)]\tLoss: 0.690799\n",
    "Train Epoch: 1 [2560/40479 (6%)]\tLoss: 0.686433\n",
    "Train Epoch: 1 [5120/40479 (13%)]\tLoss: 0.681382\n",
    "Train Epoch: 1 [7680/40479 (19%)]\tLoss: 0.673910\n",
    "Train Epoch: 1 [10240/40479 (25%)]\tLoss: 0.667018\n",
    "Train Epoch: 1 [12800/40479 (31%)]\tLoss: 0.656438\n",
    "Train Epoch: 1 [15360/40479 (38%)]\tLoss: 0.645444\n",
    "Train Epoch: 1 [17920/40479 (44%)]\tLoss: 0.628610\n",
    "Train Epoch: 1 [20480/40479 (50%)]\tLoss: 0.600967\n",
    "Train Epoch: 1 [23040/40479 (57%)]\tLoss: 0.570082\n",
    "Train Epoch: 1 [25600/40479 (63%)]\tLoss: 0.520596\n",
    "Train Epoch: 1 [28160/40479 (69%)]\tLoss: 0.465080\n",
    "Train Epoch: 1 [30720/40479 (75%)]\tLoss: 0.412709\n",
    "Train Epoch: 1 [33280/40479 (82%)]\tLoss: 0.365693\n",
    "Train Epoch: 1 [35840/40479 (88%)]\tLoss: 0.357215\n",
    "Train Epoch: 1 [38400/40479 (94%)]\tLoss: 0.340456\n",
    "\n",
    "    \n",
    "\n",
    "https://discuss.pytorch.org/t/feedback-on-pytorch-for-kaggle-competitions/2252\n",
    "\n",
    "https://discuss.pytorch.org/t/multi-label-classification-in-pytorch/905/13\n",
    "@AjayTalati\n",
    "\n",
    "Either after your last fc you do a sigmoid and then you use BCELoss or F.binary_crossentropy as your criterion/lossfunction\n",
    "\n",
    "Or you directly use MultiLabelSoftMarginLoss as your loss function (it comes with sigmoid inside)\n",
    "\n",
    "Now once you have your prediction, you need to threshold. 0.5 is the default naive way but it's probably not optimal. In any case, once you get there, great !\n",
    "\n",
    "Next part is technical optimization, you can do Multilabel classification without\n",
    "\n",
    "Regarding the threshold, you might want to optimize either a common threshold for all your outputs (it can be 0.2, 0.5, 0.123456 who knows) or optimize a threshold per label class, especially if your classes as unbalanced.\n",
    "You will need a solid validation set and a MultiLabel evaluation metrics (Hamming Loss, F1-score, Fbeta score).\n",
    "\n",
    "An example code for the first strategy is here on Kaggle2.\n",
    "\n",
    "For the second strategy, I'm deep into various papers myself so I can't help yet.\n",
    "One thing to keep in mind is your \"best threshold\" will probably overfit the validation set, so use regularization, cross-validation or other anti-overfitting strategy.\n",
    "\n",
    "https://discuss.pytorch.org/t/equivalent-of-tensorflows-sigmoid-cross-entropy-with-logits-in-pytorch/1985/11\n",
    "@AjayTalati I managed to use BCELoss, binary_crossentropy and MultiLabelSoftMarginLoss on a MultiLabel problem\n",
    "\n",
    "Here is the basic code\n",
    "\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        # data, target = data.cuda(async=True), target.cuda(async=True) # On GPU\n",
    "        data, target = Variable(data), Variable(target)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.binary_cross_entropy(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 10 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.data[0]))\n",
    "And the source is here6.\n",
    "\n",
    "For BCELoss you can use criterion = BCELoss() and then loss = criterion(output, target) but as @Misha_E said, the NN must return a sigmoid activation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
