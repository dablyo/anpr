{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "automated number plate recognization using vgg model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path\n",
    "import random\n",
    "import cv2\n",
    "import math\n",
    "from scipy import ndimage\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torch.utils.data as torch_utils_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DIGITS = \"0123456789\"\n",
    "LETTERS = \"ABCDEFGHIJKLMNOPQRSTUVWXYZ\"\n",
    "#PROVINCE=\"黑吉辽京津内冀鲁豫徽苏沪浙赣闽粤鄂湘云贵川渝藏青宁新陕甘宁晋\" #30\n",
    "CHARS = LETTERS + DIGITS\n",
    "NPLEN=7\n",
    "NUM_CLASSES=1+len(CHARS)*NPLEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "conv=nn.Sequential(\n",
    "            nn.Conv2d(1,64,kernel_size=3,padding=1), #layer1, inputs single channel,224*224\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64,64,kernel_size=3,padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2,stride=2),\n",
    "            nn.Conv2d(64,128,kernel_size=3,padding=1), #layer2 inputs 64 channel,112*112\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(128,128,kernel_size=3,padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2,stride=2),\n",
    "            nn.Conv2d(128,256,kernel_size=3,padding=1), #layer3 inputs 128 channel,56*56\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256,256,kernel_size=3,padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256,256,kernel_size=3,padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2,stride=2),\n",
    "            nn.Conv2d(256,512,kernel_size=3,padding=1), #layer4 inputs 256 channel,28*28\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(512,512,kernel_size=3,padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(512,512,kernel_size=3,padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2,stride=2),\n",
    "            nn.Conv2d(512,512,kernel_size=3,padding=1), #layer5 inputs 512 channel,14*14\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(512,512,kernel_size=3,padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(512,512,kernel_size=3,padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2,stride=2)\n",
    "    )\n",
    "\n",
    "class vgg16train(nn.Module):\n",
    "    def __init__(self): #36*7+1=253   36*6+1=217\n",
    "        super(vgg16train,self).__init__()\n",
    "        self.features=conv\n",
    "        self.classifier=nn.Sequential(\n",
    "            nn.Linear(512 * 7 * 7, 4096),\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096, 2048),\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(2048, num_classes)\n",
    "        )\n",
    "        #initialize_weights\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "                if m.bias is not None:\n",
    "                    m.bias.data.zero_()\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                n = m.weight.size(1)\n",
    "                m.weight.data.normal_(0, 0.01)\n",
    "                m.bias.data.zero_()\n",
    "    def forward(self,x):\n",
    "        x=self.features(x)\n",
    "        x=x.view(x.size(0),-1)\n",
    "        x=self.classifier(x)\n",
    "        return x\n",
    "    \n",
    "class vgg16detect(nn.Module):    \n",
    "    def __init__(self):\n",
    "        super(vgg16detect,self).__init__()\n",
    "        self.features=conv\n",
    "        self.classifier=nn.Sequential(\n",
    "            nn.Conv2d(512,4096,kernel_size=7,padding=1),  #padding=1?\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(4096,2048,kernel_size=3,padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(4096,num_classes,kernel_size=1,padding=1),\n",
    "            #nn.ReLU(inplace=True),\n",
    "        )\n",
    "    def forward(self,x):  #是否需要\n",
    "        x=self.features(x)\n",
    "        x=x.view(x.size(0),-1)\n",
    "        x=self.classifier(x)\n",
    "        return x    \n",
    "\n",
    "class anprmodel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(anprmodel,self).__init__()\n",
    "        self.num_classes=NUM_CLASSES\n",
    "        self.conv1=nn.Conv2d(1,48,kernel_size=5,padding=2)\n",
    "        self.pool1=nn.MaxPool2d(kernel_size=2,stride=2)\n",
    "        self.conv2=nn.Conv2d(48,64,kernel_size=5,padding=2)\n",
    "        self.pool2=nn.MaxPool2d(kernel_size=(2,1),stride=(2,1))      #(kH,kW)\n",
    "        self.conv3=nn.Conv2d(64,128,kernel_size=5,padding=2)\n",
    "        self.pool3=nn.MaxPool2d(kernel_size=(2,2),stride=(2,2))        \n",
    "        self.fc1=nn.Linear(32*8*128,2048)\n",
    "        self.fc2=nn.Linear(2048,NUM_CLASSES)\n",
    "        \n",
    "    def forward(self,x): \n",
    "        x=F.relu(self.pool1(self.conv1(x)))  #224*224  128*64\n",
    "        x=F.relu(self.pool2(self.conv2(x)))  #112*112   64*32\n",
    "        x=F.relu(self.pool3(self.conv3(x)))  #56*56       64*16\n",
    "        x=x.view(-1,32*8*128)                        #32*8\n",
    "        #x=x.view(-1,28*28*128)                   #28*28\n",
    "        x=F.relu(self.fc1(x))\n",
    "        x=self.fc2(x)                                       #253\n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class NPSET(torch_utils_data.Dataset):\n",
    "    picroot='np'\n",
    "   \n",
    "    def code_to_vec(self,p, code):\n",
    "        def char_to_vec(c):\n",
    "            y = np.zeros((len(CHARS),))\n",
    "            y[CHARS.index(c)] = 1.0\n",
    "            return y\n",
    "        c = np.vstack([char_to_vec(c) for c in code])\n",
    "        return np.concatenate([[1. if p else 0], c.flatten()])\n",
    "\n",
    "    def __getitem__(self,index):\n",
    "        label,img=self.labels[index], self.dataset[index]\n",
    "        if self.data_transform is not None:\n",
    "            img=self.data_transform(img)\n",
    "        labelarray=self.code_to_vec(1,label)\n",
    "        #if self.label_transform is not None:\n",
    "        #    labelarray=self.label_transform(labelarray)\n",
    "        return img,labelarray\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "    def __init__(self,root,data_transform=None):\n",
    "        self.picroot=root\n",
    "        self.data_transform=data_transform\n",
    "\n",
    "        if not os.path.exists(self.picroot):\n",
    "            raise RuntimeError('{} doesnot exists'.format(self.picroot))\n",
    "        for root,dnames,filenames in os.walk(self.picroot):\n",
    "            imgs=np.ndarray(shape=(len(filenames),1,64,128),dtype=np.float)  #batch,channel,height,width\n",
    "            labels=[]\n",
    "            i=0\n",
    "            for filename in filenames:\n",
    "                picfilename=os.path.join(self.picroot,filename)  #file name:\n",
    "                im=cv2.imread(picfilename,cv2.IMREAD_GRAYSCALE)\n",
    "                #im=cv2.resize(im,(224,224))\n",
    "                #(thresh, im) = cv2.threshold(im, 32, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)\n",
    "                #im=cv2.erode(im,self.kernel)\n",
    "                #im=cv2.dilate(im,self.kernel)\n",
    "                #im=cv2.GaussianBlur(im,(5,5),0.1)\n",
    "                #(thresh, im) = cv2.threshold(im, 32, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)\n",
    "                imgs[i][0]=im/255\n",
    "                m=filename.split('_')  #filename style: xxxxxxxx_xxxxxxx_x.png\n",
    "                labels.append(m[1])\n",
    "                i=i+1\n",
    "            self.dataset=imgs\n",
    "            self.labels=labels\n",
    "            self.len=len(filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model=anprmodel()\n",
    "#model.features=torch.nn.DataParallel(model.features)\n",
    "#model.cuda()\n",
    "#cudnn.benchmark=True\n",
    "batch_size=4\n",
    "data_transform=transforms.Compose([transforms.ToTensor(),\n",
    "                              transforms.Normalize((0.5,), (0.5,)),\n",
    "                             ])\n",
    "npset = NPSET(root='/home/wang/git/anpr/np', data_transform=data_transform)\n",
    "nploader = torch.utils.data.DataLoader(npset, batch_size=batch_size, shuffle=False, num_workers=1)  #train\n",
    "npvalset=NPSET(root='/home/wang/git/anpr/npval', data_transform=data_transform)\n",
    "npvalloader=torch.utils.data.DataLoader(npvalset, batch_size=batch_size, shuffle=False, num_workers=1) #validate\n",
    "criterion=nn.MultiLabelMarginLoss()\n",
    "optimizer=torch.optim.SGD(model.parameters(),0.1,momentum=0.9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "res_sum=0\n",
    "res_cnt=0\n",
    "res_avg=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for epoch in range(0,1):\n",
    "    #Sets the learning rate to the initial LR decayed by 10 every 30 epochs\n",
    "    lr=0.1*(0.1**(epoch//30))\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr']=lr\n",
    "    #train\n",
    "    model.train()\n",
    "    for i,data in enumerate(nploader):\n",
    "        inputs,targets = data\n",
    "        #target=target.cuda()\n",
    "        input_var=torch.autograd.Variable(inputs)\n",
    "        targets=torch.LongTensor(np.array(targets.numpy(),np.long))\n",
    "        target_var=torch.autograd.Variable(targets)\n",
    "        output=model(input_var)\n",
    "        #porcess loss\n",
    "        loss=criterion(output,target_var)\n",
    "        \n",
    "        # compute gradient and do SGD step\n",
    "        #optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        #\n",
    "        if i% 12 == 0:\n",
    "             print('Train Epoch: {} [{}/{} ({:.0f}%)]\\\\tLoss: {:.6f}'.format(\n",
    "                  epoch, i * len(data), len(nploader.dataset),\n",
    "                  100. * i / len(nploader), loss.data[0]))\n",
    "        \n",
    "    #validate\n",
    "    model.eval()\n",
    "    for i, data in enumerate(npvalloader):\n",
    "        (inputs, target)=data\n",
    "        #target = target.cuda()\n",
    "        input_var = torch.autograd.Variable(inputs, volatile=True)\n",
    "        target_var = torch.autograd.Variable(target, volatile=True)\n",
    "        # compute output\n",
    "        output = model(input_var)\n",
    "        #porcess loss\n",
    "        o=torch.FloatTensor(np.reshape(output.data.numpy()[:,1:],(-1,len(CHARS))))\n",
    "        t=torch.LongTensor(np.array(np.reshape(target_var.data.numpy()[:,1:],(-1,len(CHARS))),np.long))\n",
    "        chararcter_loss=cerition(torch.autograd.Variable(o), torch.autograd.Variable(t))\n",
    "        #\n",
    "        bo=torch.FloatTensor(output.data.numpy()[:,1:])\n",
    "        bt=\n",
    "        b=0,d=0\n",
    "        for k < o.size(0)\n",
    "        #\n",
    "        if i% 12 == 0:\n",
    "             print('Test Epoch: {} [{}/{} ({:.0f}%)]\\\\tLoss: {:.6f}'.format(\n",
    "                  epoch, i * len(data), len(nploader.dataset),\n",
    "                  100. * i / len(nploader), loss.data[0]))\n",
    "        prec1=top1.avg\n",
    "        # remember best prec@1 and save checkpoint\n",
    "        is_best = prec1 > best_prec1\n",
    "        best_prec1 = max(prec1, best_prec1)\n",
    "    if is_best:\n",
    "        torch.save({\n",
    "            'epoch': epoch + 1,\n",
    "            'arch':vgg16,\n",
    "            'state_dict': model.state_dict(),\n",
    "            'best_prec1': best_prec1,\n",
    "        })"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
