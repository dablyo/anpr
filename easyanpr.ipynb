{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#车牌图像训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import os.path\n",
    "import math\n",
    "import random\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.mlab as mlab\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "conv=nn.Sequential(\n",
    "            nn.Conv2d(1,64,kernel_size=3,padding=1), #layer1, inputs single channel,256*128\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64,64,kernel_size=3,padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2,stride=2),\n",
    "            nn.Conv2d(64,128,kernel_size=3,padding=1), #layer2 inputs 64 channel,128*64\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(128,128,kernel_size=3,padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2,stride=2),\n",
    "            nn.Conv2d(128,256,kernel_size=3,padding=1), #layer3 inputs 128 channel,64*32\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256,256,kernel_size=3,padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256,256,kernel_size=3,padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2,stride=2),\n",
    "            nn.Conv2d(256,512,kernel_size=3,padding=1), #layer4 inputs 256 channel,32*16\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(512,512,kernel_size=3,padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(512,512,kernel_size=3,padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2,stride=2),\n",
    "            nn.Conv2d(512,512,kernel_size=3,padding=1), #layer5 inputs 512 channel,16*8\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(512,512,kernel_size=3,padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(512,512,kernel_size=3,padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2,stride=2)\n",
    "    )\n",
    "\n",
    "class vgg16train(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(vgg16train,self).__init__()\n",
    "        self.features=conv\n",
    "        self.classifier=nn.Sequential(\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(512 * 8 * 4, 4096),                             #connect: layter: inputs 512, 8*4\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096, 2048),\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(2048, 2)\n",
    "        )\n",
    "        #initialize_weights\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "                if m.bias is not None:\n",
    "                    m.bias.data.zero_()\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                n = m.weight.size(1)\n",
    "                m.weight.data.normal_(0, 0.01)\n",
    "                m.bias.data.zero_()\n",
    "    def forward(self,x):\n",
    "        x=self.features(x)\n",
    "        x=x.view(x.size(0),-1)\n",
    "        x=self.classifier(x)\n",
    "        return x\n",
    "\n",
    "class npModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(npModel, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=3,padding=1)   \n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=3,padding=1) \n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(20*8*16, 100)   #16*32*20\n",
    "        self.fc2 = nn.Linear(100, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))                                #32*64\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))   #16*32\n",
    "        x = x.view(-1, 20*8*16)      \n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count    \n",
    "        \n",
    "def accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the precision@k for the specified values of k\"\"\"\n",
    "    maxk = max(topk)\n",
    "    batch_size = target.size(0)\n",
    "\n",
    "    _, pred = output.topk(maxk, 1, True, True)   #pred是索引/位置指示\n",
    "    pred = pred.t()                                                 #转置\n",
    "    correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "    res = []\n",
    "    for k in topk:\n",
    "        correct_k = correct[:k].view(-1).float().sum(0)\n",
    "        res.append(correct_k.mul_(100.0 / batch_size))\n",
    "    return res        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#get back picture 生成反例图片/背景图片\n",
    "OUTPUT_SHAPE=(128,256)\n",
    "SRCPICDIR='/home/wang/git/deep-anpr/bgs'\n",
    "DSTPICDIR='/home/wang/git/nppic/nproot/back'\n",
    "SRC_NUM_PIC=10000\n",
    "DST_NUM_PIC=500\n",
    "def generate_bg(num_bg_img):\n",
    "    found=False\n",
    "    while not found :\n",
    "        fname=\"{}/{:08d}.jpg\".format(SRCPICDIR,random.randint(0, SRC_NUM_PIC - 1))\n",
    "        bg=cv2.imread(fname,cv2.CV_LOAD_IMAGE_GRAYSCALE)\n",
    "        if(bg.shape[0]>=OUTPUT_SHAPE[0]  and bg.shape[1]>=OUTPUT_SHAPE[1]):\n",
    "            found=True\n",
    "    x=random.randint(0,bg.shape[1]-OUTPUT_SHAPE[1])\n",
    "    y=random.randint(0,bg.shape[0]-OUTPUT_SHAPE[0])\n",
    "    return bg[y:y+OUTPUT_SHAPE[0],x:x+OUTPUT_SHAPE[1]]\n",
    "    \n",
    "if os.path.exists(DSTPICDIR):\n",
    "    raise IOError,DSTPICDIR+\" has been exists\" \n",
    "os.mkdir(DSTPICDIR)            \n",
    "i=0\n",
    "while i<600:\n",
    "    #bg=generate_bg(SRC_NUM_PIC)\n",
    "    fname=os.path.join(DSTPICDIR,\"{:4d}.jpg\".format(random.randint(0,9999)))\n",
    "    #cv2.imwrite(fname,generate_bg(SRC_NUM_PIC))\n",
    "    i=i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107.505113917 3847.16795699\n"
     ]
    }
   ],
   "source": [
    "#mean and variance 得到均值和方差\n",
    "TRAINDIR='/home/wang/git/nppic/nproot'\n",
    "f=[]\n",
    "for parent,dirnames,filenames in os.walk(TRAINDIR):\n",
    "     for i,fname in enumerate(filenames):\n",
    "        f.append(os.path.join(parent,fname))\n",
    "img=np.ndarray((len(f),128,256))\n",
    "for i,fname in enumerate(f):\n",
    "    img[i]=cv2.imread(os.path.join(TRAINDIR,fname),cv2.CV_LOAD_IMAGE_GRAYSCALE)\n",
    "mean=np.mean(img)\n",
    "var=np.var(img)\n",
    "print mean,var\n",
    "#不除以255：mean/var:107.505113917 3847.16795699\n",
    "#除以255，mean/var:0.42312632171/0.0598781834145\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#def make_scaled_ims(im, min_shape):\n",
    "#    ratio = 1. / 2 ** 0.5\n",
    "#        yield cv2.resize(im, (shape[1], shape[0]))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def gray_loader(path):#input 128*256\n",
    "    im=cv2.imread(path,cv2.CV_LOAD_IMAGE_GRAYSCALE)\n",
    "    return im\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over\n"
     ]
    }
   ],
   "source": [
    "batch_size=10\n",
    "data_transform=transforms.Compose([transforms.ToTensor(),\n",
    "                              transforms.Normalize((107.5051,), (3847.1679,)),\n",
    "                             ])\n",
    "npset = datasets.ImageFolder(root='/home/wang/git/nppic/nproot', \n",
    "                             transform=data_transform,loader=gray_loader)\n",
    "nploader = torch.utils.data.DataLoader(npset, batch_size=batch_size, shuffle=True, \n",
    "                                       num_workers=1)  #train\n",
    "npvalset=datasets.ImageFolder(root='/home/wang/git/nppic/npval', \n",
    "                              transform=data_transform,loader=gray_loader)\n",
    "npvalloader=torch.utils.data.DataLoader(npvalset, batch_size=batch_size, shuffle=True, \n",
    "                                        num_workers=1) #validate\n",
    "print 'over'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over\n"
     ]
    }
   ],
   "source": [
    "model=vgg16train()\n",
    "model.cuda()\n",
    "criterion = nn.CrossEntropyLoss() # use a Classification Cross-Entropy loss\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "print 'over'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  500] currnet los: 0.68745, ave loss: 0.69291\n",
      "[2,  500] currnet los: 0.69497, ave loss: 0.69179\n",
      "[3,  500] currnet los: 0.67789, ave loss: 0.69171\n",
      "[4,  500] currnet los: 0.70699, ave loss: 0.68679\n",
      "[5,  500] currnet los: 0.67425, ave loss: 0.67894\n",
      "[6,  500] currnet los: 0.47749, ave loss: 0.62289\n",
      "[7,  500] currnet los: 0.00822, ave loss: 0.23472\n",
      "[8,  500] currnet los: 0.00332, ave loss: 0.05390\n",
      "[9,  500] currnet los: 0.11020, ave loss: 0.04216\n",
      "[10,  500] currnet los: 0.05372, ave loss: 0.03468\n",
      "[11,  500] currnet los: 0.00481, ave loss: 0.02191\n",
      "[12,  500] currnet los: 0.03106, ave loss: 0.02313\n",
      "[13,  500] currnet los: 0.00013, ave loss: 0.02183\n",
      "[14,  500] currnet los: 0.03563, ave loss: 0.01895\n",
      "[15,  500] currnet los: 0.01196, ave loss: 0.02631\n",
      "[16,  500] currnet los: 0.00515, ave loss: 0.03786\n",
      "[17,  500] currnet los: 0.01267, ave loss: 0.04407\n",
      "[18,  500] currnet los: 0.01212, ave loss: 0.01058\n",
      "[19,  500] currnet los: 0.00000, ave loss: 0.00254\n",
      "[20,  500] currnet los: 0.00037, ave loss: 0.00828\n"
     ]
    }
   ],
   "source": [
    "#Train\n",
    "losses=AverageMeter()\n",
    "model.train()\n",
    "for epoch in range(20):\n",
    "    losses.reset()\n",
    "    for _, (datas,targets) in enumerate(nploader):\n",
    "        datas=torch.unsqueeze(datas,1)\n",
    "        datas_var,targets_var=torch.autograd.Variable(datas),torch.autograd.Variable(targets)\n",
    "        datas_var=datas_var.cuda()\n",
    "        targets_var=targets_var.cuda()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs_var = model(datas_var)\n",
    "        loss = criterion(outputs_var, targets_var)\n",
    "        loss.backward()        \n",
    "        optimizer.step()\n",
    "        #loss\n",
    "        losses.update(loss.data[0],datas_var.data.size(0))  # datas size(0) is batch_size of input\n",
    "        if losses.count % 500 == 0:\n",
    "            print ('[%d, %4d] currnet los: %.5f, ave loss: %.5f' %(epoch+1,losses.count,loss.data[0], losses.avg)) \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(),'./plate.weight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is: 100.00\n"
     ]
    }
   ],
   "source": [
    "#validate\n",
    "prediction=AverageMeter()\n",
    "model.eval()\n",
    "for _, (datas,targets) in enumerate(npvalloader):\n",
    "    datas=torch.unsqueeze(datas,1)\n",
    "    datas_var,targets_var=torch.autograd.Variable(datas),torch.autograd.Variable(targets)\n",
    "    datas_var=datas_var.cuda()\n",
    "    targets_var=targets_var.cuda()    \n",
    "    outputs_var = model(datas_var)\n",
    "    prec=accuracy(outputs_var.data,targets_var.data)   #40% will return 40\n",
    "    prediction.update(prec[0].cpu().numpy()[0],datas_var.data.size(0))\n",
    "    \n",
    "#print(' accuracy is{val.avg:%.2f}'.format(val=prediction))\n",
    "print ('accuracy is: %.2f' %(prediction.avg)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over\n"
     ]
    }
   ],
   "source": [
    "net=vgg16train()\n",
    "net.load_state_dict(torch.load('/home/wang/git/anpr/plate.weight'))\n",
    "net.cuda()\n",
    "print('over')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'plate': 1, 'back': 0}\n"
     ]
    }
   ],
   "source": [
    "nptestset=datasets.ImageFolder(root='/home/wang/git/nppic/npr', \n",
    "                              transform=data_transform,loader=gray_loader)\n",
    "nptestloader=torch.utils.data.DataLoader(npvalset, batch_size=1, shuffle=False, \n",
    "                                        num_workers=1) #validate\n",
    "def find_classes(dir):\n",
    "    classes = [d for d in os.listdir(dir) if os.path.isdir(os.path.join(dir, d))]\n",
    "    classes.sort()\n",
    "    class_to_idx = {classes[i]: i for i in range(len(classes))}\n",
    "    return classes, class_to_idx\n",
    "classes,class_to_idx=find_classes('/home/wang/git/nppic/npr')\n",
    "print class_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 1\n",
       "[torch.LongTensor of size 1]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nptest=iter(nptestloader)\n",
    "datas,targets=nptest.next()\n",
    "targets\n",
    "#targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over\n"
     ]
    }
   ],
   "source": [
    "datas=torch.unsqueeze(datas,1)\n",
    "datas_var,targets_var=torch.autograd.Variable(datas),torch.autograd.Variable(targets)\n",
    "datas_var=datas_var.cuda()\n",
    "targets_var=targets_var.cuda()   \n",
    "outputs_var=net(datas_var)\n",
    "print('over')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "-10.3887   8.9537\n",
       "[torch.cuda.FloatTensor of size 1x2 (GPU 0)]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      " 1\n",
      "[torch.cuda.LongTensor of size 1x1 (GPU 0)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classesc=['back','plate']\n",
    "_,pred=torch.max(outputs_var,1)\n",
    "print pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      " 1\n",
      "[torch.cuda.LongTensor of size 1x1 (GPU 0)]\n",
      "\n",
      "plate\n"
     ]
    }
   ],
   "source": [
    "p=pred.cpu().data.numpy()\n",
    "for i,idx in enumerate(p):\n",
    "    print classesc[idx[0]]\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#mean and variance\n",
    "TRAINDIR='/home/wang/git/nppic/nproot/plate'\n",
    "f=[]\n",
    "for parent,dirnames,filenames in os.walk(TRAINDIR):\n",
    "    for filename in filenames:\n",
    "        f.append(filename)\n",
    "img=np.ndarray((len(f),128,256))\n",
    "for i,fname in enumerate(f):\n",
    "    img[i]=cv2.imread(os.path.join(TRAINDIR,fname),cv2.CV_LOAD_IMAGE_GRAYSCALE)\n",
    "\n",
    "img=img/255  #[0,1]\n",
    "\n",
    "mean=np.mean(img)   #-0.18262765251608459\n",
    "var=np.var(img)             #0.21571192247129692\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
