{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#车牌图像训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import os.path\n",
    "import math\n",
    "import random\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.mlab as mlab\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conv=nn.Sequential(\n",
    "            nn.Conv2d(1,64,kernel_size=3,padding=1), #layer1, inputs single channel,256*128\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64,64,kernel_size=3,padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2,stride=2),\n",
    "            nn.Conv2d(64,128,kernel_size=3,padding=1), #layer2 inputs 64 channel,128*64\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(128,128,kernel_size=3,padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2,stride=2),\n",
    "            nn.Conv2d(128,256,kernel_size=3,padding=1), #layer3 inputs 128 channel,64*32\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256,256,kernel_size=3,padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256,256,kernel_size=3,padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2,stride=2),\n",
    "            nn.Conv2d(256,512,kernel_size=3,padding=1), #layer4 inputs 256 channel,32*16\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(512,512,kernel_size=3,padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(512,512,kernel_size=3,padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2,stride=2),\n",
    "            nn.Conv2d(512,512,kernel_size=3,padding=1), #layer5 inputs 512 channel,16*8\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(512,512,kernel_size=3,padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(512,512,kernel_size=3,padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2,stride=2)\n",
    "    )\n",
    "\n",
    "class vgg16train(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(vgg16train,self).__init__()\n",
    "        self.features=conv\n",
    "        self.classifier=nn.Sequential(\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(512 * 8 * 4, 4096),                             #connect: layter: inputs 512, 8*4\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096, 2048),\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(2048, 2)\n",
    "        )\n",
    "        #initialize_weights\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "                if m.bias is not None:\n",
    "                    m.bias.data.zero_()\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                n = m.weight.size(1)\n",
    "                m.weight.data.normal_(0, 0.01)\n",
    "                m.bias.data.zero_()\n",
    "    def forward(self,x):\n",
    "        x=self.features(x)\n",
    "        x=x.view(x.size(0),-1)\n",
    "        x=self.classifier(x)\n",
    "        return x\n",
    "\n",
    "class npModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(npModel, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=3,padding=1)   \n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=3,padding=1) \n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(20*8*16, 100)   #16*32*20\n",
    "        self.fc2 = nn.Linear(100, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))                                #32*64\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))   #16*32\n",
    "        x = x.view(-1, 20*8*16)      \n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count    \n",
    "        \n",
    "def accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the precision@k for the specified values of k\"\"\"\n",
    "    maxk = max(topk)\n",
    "    batch_size = target.size(0)\n",
    "\n",
    "    _, pred = output.topk(maxk, 1, True, True)   #pred是索引/位置指示\n",
    "    pred = pred.t()                                                 #转置\n",
    "    correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "    res = []\n",
    "    for k in topk:\n",
    "        correct_k = correct[:k].view(-1).float().sum(0)\n",
    "        res.append(correct_k.mul_(100.0 / batch_size))\n",
    "    return res        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#get back picture 生成反例图片/背景图片\n",
    "OUTPUT_SHAPE=(128,256)\n",
    "SRCPICDIR='/home/wang/git/deep-anpr/bgs'\n",
    "DSTPICDIR='/home/wang/git/nppic/nproot/back'\n",
    "SRC_NUM_PIC=10000\n",
    "DST_NUM_PIC=500\n",
    "def generate_bg(num_bg_img):\n",
    "    found=False\n",
    "    while not found :\n",
    "        fname=\"{}/{:08d}.jpg\".format(SRCPICDIR,random.randint(0, SRC_NUM_PIC - 1))\n",
    "        bg=cv2.imread(fname,cv2.CV_LOAD_IMAGE_GRAYSCALE)\n",
    "        if(bg.shape[0]>=OUTPUT_SHAPE[0]  and bg.shape[1]>=OUTPUT_SHAPE[1]):\n",
    "            found=True\n",
    "    x=random.randint(0,bg.shape[1]-OUTPUT_SHAPE[1])\n",
    "    y=random.randint(0,bg.shape[0]-OUTPUT_SHAPE[0])\n",
    "    return bg[y:y+OUTPUT_SHAPE[0],x:x+OUTPUT_SHAPE[1]]\n",
    "    \n",
    "if os.path.exists(DSTPICDIR):\n",
    "    raise IOError,DSTPICDIR+\" has been exists\" \n",
    "os.mkdir(DSTPICDIR)            \n",
    "i=0\n",
    "while i<600:\n",
    "    bg=generate_bg(SRC_NUM_PIC)\n",
    "    fname=os.path.join(DSTPICDIR,\"{:4d}.jpg\".format(random.randint(0,9999)))\n",
    "    cv2.imwrite(fname,generate_bg(SRC_NUM_PIC))\n",
    "    i=i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#mean and variance 得到均值和方差\n",
    "TRAINDIR='/home/wang/git/nppic/meanval'\n",
    "f=[]\n",
    "for parent,dirnames,filenames in os.walk(TRAINDIR):\n",
    "    for filename in filenames:\n",
    "        f.append(filename)\n",
    "        \n",
    "img=np.ndarray((len(f),128,256))\n",
    "for i,fname in enumerate(f):\n",
    "    img[i]=cv2.imread(os.path.join(TRAINDIR,fname),cv2.CV_LOAD_IMAGE_GRAYSCALE)\n",
    "mean=np.mean(img)\n",
    "var=np.var(img)\n",
    "print mean,var\n",
    "#another method, equal to mean/var of numpy\n",
    "#mean=0\n",
    "#cnt=0\n",
    "#i=np.transpose(img,(1,2,0))    \n",
    "#for r,row in enumerate(i):\n",
    "#    for c,column in enumerate(row):\n",
    "#        for idx,dot in enumerate(column):\n",
    "#            mean=mean+dot\n",
    "#            cnt=cnt+1\n",
    "#mean=mean/cnt            \n",
    "#v=0\n",
    "#cnt=0\n",
    "#for r,row in enumerate(i):\n",
    "#    for c,column in enumerate(row):\n",
    "#        for idx,dot in enumerate(column):\n",
    "#            v=v+(dot-mean)**2\n",
    "#            cnt=cnt+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_scaled_ims(im, min_shape):\n",
    "    ratio = 1. / 2 ** 0.5\n",
    "        yield cv2.resize(im, (shape[1], shape[0]))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gray_loader(path):#input 128*256\n",
    "    return cv2.imread(path,cv2.CV_LOAD_IMAGE_GRAYSCALE)\n",
    "    #img=cv2.imread(path,cv2.CV_LOAD_IMAGE_GRAYSCALE)\n",
    "    #return cv2.resize(img,(64,32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over\n"
     ]
    }
   ],
   "source": [
    "batch_size=5\n",
    "data_transform=transforms.Compose([transforms.ToTensor(),\n",
    "                              transforms.Normalize((107.897212036,), (3893.57887653,)),\n",
    "                             ])\n",
    "npset = datasets.ImageFolder(root='/home/wang/git/nppic/nproot', \n",
    "                             transform=data_transform,loader=gray_loader)\n",
    "nploader = torch.utils.data.DataLoader(npset, batch_size=batch_size, shuffle=True, \n",
    "                                       num_workers=1)  #train\n",
    "npvalset=datasets.ImageFolder(root='/home/wang/git/nppic/npval', \n",
    "                              transform=data_transform,loader=gray_loader)\n",
    "npvalloader=torch.utils.data.DataLoader(npvalset, batch_size=batch_size, shuffle=False, \n",
    "                                        num_workers=1) #validate\n",
    "print 'over'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over\n"
     ]
    }
   ],
   "source": [
    "model=vgg16train()\n",
    "#model=npModel()\n",
    "#model.cuda()\n",
    "criterion = nn.CrossEntropyLoss() # use a Classification Cross-Entropy loss\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "print 'over'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Train\n",
    "losses=AverageMeter()\n",
    "model.train()\n",
    "for epoch in range(4):\n",
    "    losses.reset()\n",
    "    for _, (datas,targets) in enumerate(nploader):\n",
    "        datas=torch.unsqueeze(datas,1)\n",
    "        datas_var,targets_var=torch.autograd.Variable(datas),torch.autograd.Variable(targets)\n",
    "        #datas_var=datas_var.cuda()\n",
    "        #targets_var=targets_var.cuda()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs_var = model(datas_var)\n",
    "        loss = criterion(outputs_var, targets_var)\n",
    "        loss.backward()        \n",
    "        optimizer.step()\n",
    "        #loss\n",
    "        losses.update(loss.data[0],datas_var.data.size(0))  # datas size(0) is batch_size of input\n",
    "        if losses.count % 100 == 0:\n",
    "            print ('[%d, %4d] currnet los: %.5f, ave loss: %.5f' %(epoch+1,losses.count,loss.data[0], losses.avg)) \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(),'./plate.weight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#validate\n",
    "prediction=AverageMeter()\n",
    "model.eval()\n",
    "for _, (datas,targets) in enumerate(npvalloader):\n",
    "    datas=torch.unsqueeze(datas,1)\n",
    "    datas_var,targets_var=torch.autograd.Variable(datas),torch.autograd.Variable(targets)\n",
    "    #datas_var=datas_var.cuda()\n",
    "    #targets_var=targets_var.cuda()    \n",
    "    optimizer.zero_grad()\n",
    "    outputs_var = model(datas_var)\n",
    "    prec=accuracy(outputs_var.data,targets_var.data)   #40% will return 40\n",
    "    prediction.update(prec[0].cpu().numpy()[0],datas_var.data.size(0))\n",
    "    \n",
    "#print(' accuracy is{val.avg:%.2f}'.format(val=prediction))\n",
    "print ('accuracy is: %.2f' %(prediction.avg)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sm=nn.Softmax()\n",
    "d=sm(outputs_var)\n",
    "print d\n",
    "print '------------'\n",
    "print torch.max(d,1)\n",
    "#print '------------'\n",
    "#print datas_var.data.size()\n",
    "#print '------------'\n",
    "#print outputs_var.data\n",
    "#print '------------'\n",
    "#print torch.max(outputs_var.data,1)\n",
    "#print '------------'\n",
    "#print targets_var.data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#test\n",
    "#原图传入，如果概率小于50%，则认为不存在\n",
    "#按照上一次图的70%截取ROI，步长为短边×(1-30%)×1/4进行滑动，生成ROI集合，\n",
    "#        进行检测，取概率最大的一个进行迭代，直到\n",
    "#  1. 某一次检测的所有ROI集合中成员检测概率都不超过50%\n",
    "TESTPICDIR='/home/wang/git/nppic/su_np_gray/20170221_143111_gray.jpg'\n",
    "OUTPUTDIR='/home/wang/git/nppic'\n",
    "################\n",
    "#intput,simgle channel\n",
    "#the returning: \n",
    "# img list\n",
    "#or none if 70% of img shape[0] < OUT_SHAPE[0] or  img shape[1] < OUT_SHAPE[1]\n",
    "#or step < 2\n",
    "def get_roi_set(img):\n",
    "    rect_y=int(img.shape[0]*0.7)\n",
    "    rect_x=int(img.shape[1]*0.7)\n",
    "    if rect_y<OUTPUT_SHAPE[0] or rect_x<OUTPUT_SHAPE[1]:\n",
    "        return None\n",
    "    step=int(min(img.shape[0]*0.3,img.shape[1]*0.3)//4)\n",
    "    if step<2:  \n",
    "        return None\n",
    "    \n",
    "    cordinate_x=0\n",
    "    cordinate_y=0 #ROI右上基准\n",
    "    res=[]\n",
    "    while cordinate_y+rect_y < img.shape[0]:\n",
    "        cordinate_x=0\n",
    "        while cordinate_x+rect_x < img.shape[1]:\n",
    "            res.append(img[cordinate_y:cordinate_y+rect_y, cordinate_x:cordinate_x+rect_x].copy())\n",
    "            cordinate_x += step\n",
    "        #the  right column\n",
    "        if (cordinate_x+rect_x-img.shape[1]) < rect_y-128 :   #there are 128 pixels at least in the right rest\n",
    "            tt=np.zeros((rect_y,rect_x),dtype=np.uint8)\n",
    "            tt[0:rect_y,0: img.shape[1]-cordinate_x]=img[cordinate_y:cordinate_y+rect_y, cordinate_x:]\n",
    "            res.append(tt.copy())\n",
    "        cordinate_y += step\n",
    "    #the bottom row    \n",
    "    if (cordinate_y+rect_y-img.shape[0]) < rect_x-64: #there are 64 pixels at least in the bottom rest\n",
    "        cordinate_x=0\n",
    "        while cordinate_x+rect_x < img.shape[1]:\n",
    "            tt=np.zeros((rect_y,rect_x),dtype=np.uint8)\n",
    "            tt[0:img.shape[0]-cordinate_y, 0:rect_x]=img[cordinate_y:, cordinate_x:cordinate_x+rect_x]\n",
    "            res.append(tt.copy())\n",
    "            cordinate_x+=step\n",
    "        #the buttom right corner\n",
    "        if (cordinate_x+rect_x-img.shape[1]) < rect_y-128 :\n",
    "            tt=np.zeros((rect_y,rect_x),dtype=np.uint8)\n",
    "            tt[0:img.shape[0]-cordinate_y, 0: img.shape[1]-cordinate_x]=img[cordinate_y:, cordinate_x:]\n",
    "            res.append(tt.copy())\n",
    "    return res\n",
    "\n",
    "img=cv2.imread(TESTPICDIR,cv2.CV_LOAD_IMAGE_GRAYSCALE)\n",
    "res=get_roi_set(img)\n",
    "for i,img in enumerate(res):\n",
    "    cv2.imwrite(os.path.join(OUTPUTDIR,\"{:04d}.jpg\".format(i)),img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#mean and variance\n",
    "TRAINDIR='/home/wang/git/nppic/nproot/plate'\n",
    "f=[]\n",
    "for parent,dirnames,filenames in os.walk(TRAINDIR):\n",
    "    for filename in filenames:\n",
    "        f.append(filename)\n",
    "img=np.ndarray((len(f),128,256))\n",
    "for i,fname in enumerate(f):\n",
    "    img[i]=cv2.imread(os.path.join(TRAINDIR,fname),cv2.CV_LOAD_IMAGE_GRAYSCALE)\n",
    "\n",
    "img=img/255  #[0,1]\n",
    "\n",
    "mean=np.mean(img)   #-0.18262765251608459\n",
    "var=np.var(img)             #0.21571192247129692\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#获取直方图，单通道\n",
    "def getHist(img):\n",
    "    return cv2.calcHist([img], [0], None, [256], [0.0,255.0])  \n",
    "\n",
    "#生产直方图,单通道\n",
    "def calcAndDrawHist(image, color=[255,255,255]): \n",
    "    hist= cv2.calcHist([image], [0], None, [256], [0.0,255.0])    \n",
    "    minVal, maxVal, minLoc, maxLoc = cv2.minMaxLoc(hist)    \n",
    "    histImg = np.zeros([256,256,3], np.uint8)    \n",
    "    hpt = int(0.9* 256);    \n",
    "        \n",
    "    for h in range(256):    \n",
    "        intensity = int(hist[h]*hpt/maxVal)    \n",
    "        cv2.line(histImg,(h,256), (h,256-intensity), color)    \n",
    "            \n",
    "    return histImg;#生产直方图,单通道\n",
    "\n",
    "#生成直方图，三通道，折线方式\n",
    "def calcAndDrawHistPolyline(img): \n",
    "    h = np.zeros((256,256,3)) #创建用于绘制直方图的全0图像    \n",
    "         \n",
    "    bins = np.arange(256).reshape(256,1) #直方图中各bin的顶点位置    \n",
    "    color = [ (255,0,0),(0,255,0),(0,0,255) ] #BGR三种颜色    \n",
    "    for ch, col in enumerate(color):    \n",
    "        originHist = cv2.calcHist([img],[ch],None,[256],[0,256])    \n",
    "        cv2.normalize(originHist, originHist,0,255*0.9,cv2.NORM_MINMAX)    \n",
    "        hist=np.int32(np.around(originHist))    \n",
    "        pts = np.column_stack((bins,hist))    \n",
    "        cv2.polylines(h,[pts],False,col)    \n",
    "         \n",
    "    h=np.flipud(h)\n",
    "    return h\n",
    "\n",
    "def imshow(img):\n",
    "    plt.imshow(img)\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img=cv2.imread(imgfile)#,cv2.CV_LOAD_IMAGE_GRAYSCALE) #img: [height, width, channels]\n",
    "x=img.transpose(2,0,1)\n",
    "#h=calcAndDrawHist(x[0]) #hist of channels 0 \n",
    "#imshow(h)\n",
    "#原图\n",
    "#imshow(img)\n",
    "#h=calcAndDrawHist(img)\n",
    "#imshow(h)\n",
    "#直方图均衡化\n",
    "b=cv2.equalizeHist(x[0])\n",
    "g=cv2.equalizeHist(x[1])\n",
    "r=cv2.equalizeHist(x[2])\n",
    "bgr=np.array((b,g,r))\n",
    "print bgr.shape\n",
    "img=bgr.transpose(1,2,0)  #channel,height,width -> height,width,channel\n",
    "#imshow(img)\n",
    "#点运算--二值化，灰度线性变换（改变对比度），灰度拉伸（过曝/不足），灰度均衡\n",
    "#f(dot)=k2*dot.blue+dot.green/k1+dot.red/k1\n",
    "def dotcalc((b,g,r),k1,k2):\n",
    "    return k2*b+g/k1+r/k1\n",
    "grayimg=np.zeros((img.shape[0],img.shape[1]),np.uint8)\n",
    "for h,row in enumerate(img):\n",
    "    for w,dot in enumerate(row):\n",
    "        b,g,r=dot\n",
    "        grayimg[h][w]=dotcalc((b,g,r),0.8,0.1)\n",
    "imshow(grayimg)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def imshow(img):\n",
    "    plt.imshow(img)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#http://blog.csdn.net/honghu549599aaa/article/details/51275349\n",
    "def colorDetect(image,option=0):\n",
    "    img = cv2.imread(image)\n",
    "    colorImage = img.copy()\n",
    "    _colorImage = img.copy()\n",
    "    hsv=cv2.cvtColor(img,cv2.COLOR_BGR2HSV)\n",
    "    #cv2.imshow(\"hsv\",hsv)\n",
    "    #高斯模糊\n",
    "    img = cv2.GaussianBlur(img,(5,5),0)\n",
    "    #cv2.imshow(\"hsv\",hsv)\n",
    "    # 设定蓝色的阈值\n",
    "    if(option == 0):\n",
    "        lower=np.array([100,50,50])\n",
    "        upper=np.array([140,255,255])\n",
    "    else:\n",
    "        #黄色\n",
    "        lower=np.array([15,50,50])\n",
    "        upper=np.array([40,255,255])\n",
    "    # 根据阈值构建掩模\n",
    "    mask=cv2.inRange(hsv,lower,upper)\n",
    "    # 对原图像和掩模进行位运算\n",
    "    res=cv2.bitwise_and(img,img,mask=mask)\n",
    "    gray = cv2.cvtColor(res,cv2.COLOR_BGR2GRAY)\n",
    "    #二值化\n",
    "    ret,thresh1 = cv2.threshold(gray,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "    #cv2.imshow('gray',gray)\n",
    "    #闭操作\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT,(17, 3))\n",
    "    closed = cv2.morphologyEx(thresh1, cv2.MORPH_CLOSE, kernel)\n",
    "    #cv2.imshow('closed',closed)\n",
    "    (cnts, _) = cv2.findContours(closed.copy(),cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)\n",
    "    #boxes = choose(cnts)\n",
    "    cv2.drawContours(img,cnts,-1,(0,0,255),1)\n",
    "    return img\n",
    "    imgRs = []\n",
    "    i = 0\n",
    "    for cnt in cnts:\n",
    "        rect = cv2.minAreaRect(cnt)\n",
    "        x,y,w,h = cv2.boundingRect(cnt)\n",
    "        if(w<50 or h < 15 or w>h < 1.0):\n",
    "            continue\n",
    "        #cv2.rectangle(_colorImage,(x,y),(x+w,y+h),(0,255,0),1)\n",
    "        #imgCrop = _colorImage[y:y+h,x:x+w]\n",
    "        imgRs.append((x,y,w,h,rect[2]))\n",
    "        rs = img[y:y+h,x:x+w]\n",
    "        #cv2.imshow(\"=============\"+str(name),rs)\n",
    "    #cv2.drawContours(_colorImage, [_box], -1, (0,0,255), 1)\n",
    "    #cv2.imshow(\"_colorImage\",_colorImage)\n",
    "    return imgRs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#npcolor='/home/wang/git/nppic/su_np_color/20170218_091712.jpg'\n",
    "#npcolor='/home/wang/git/nppic/su_np_color/20170220_141422.jpg'\n",
    "npcolor='/home/wang/git/nppic/su_np_color-256x128/00000113_0A9U2W1_1.png'\n",
    "\n",
    "imnp=colorDetect(npcolor)\n",
    "imshow(imnp)\n",
    "cv2.imwrite('/home/wang/git/nppic/20170218_091712.png',imnp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
