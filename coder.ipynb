{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "牌照号码训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path\n",
    "import shutil\n",
    "import cv2\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch.utils.data\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "DIGITS='01234567890'\n",
    "LETTER='ABCDEFGHJKLMNPQRSTUVWXYZ'\n",
    "PROV='川鄂赣甘贵桂黑沪冀津京吉辽鲁蒙闽宁青琼陕苏晋皖湘新豫渝粤云藏浙'\n",
    "CHAR=DIGITS+LETTER\n",
    "CLASSES=['0','1','2','3','4','5','6','7','8','9','0','A','B','C','D','E','F','G','H','J','K','L','M','N','P','Q','R','S','T','U','V','W','X','Y','Z',\n",
    "         'zh_cuan','zh_e','zh_gan','zh_gan1','zh_gui','zh_gui1','zh_hei','zh_hu','zh_ji','zh_jin','zh_jing','zh_jl','zh_liao','zh_lu','zh_meng',\n",
    "        'zh_min','zh_ning','zh_qing','zh_qiong','zh_shan','zh_su','zh_sx','zh_wan','zh_xiang','zh_xin','zh_yu','zh_yu1','zh_yue','zh_yun',\n",
    "        'zh_zang','zh_zhe']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def dirname_to_class(cname):\n",
    "    return CLASSES.index(cname)\n",
    "\n",
    "def find_classes(dir):\n",
    "    classes = [d for d in os.listdir(dir) if os.path.isdir(os.path.join(dir, d))]\n",
    "    classes.sort()\n",
    "    class_to_idx = {classes[i]: i for i in range(len(classes))}\n",
    "    return classes, class_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.norm2d=nn.BatchNorm2d(1)\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=3,padding=1)   \n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=3,padding=1) \n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(15*15*20, 1000)\n",
    "        self.fc2 = nn.Linear(1000, 65)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.norm2d(x)\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))                                #60*60\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))   #30*30\n",
    "        x = x.view(-1, 15*15*20)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x)    \n",
    "    \n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 100)\n",
    "        self.fc2 = nn.Linear(100, 34)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))                              #28*28\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2)) #12*12\n",
    "        x = x.view(-1, 4*4*20)                                                                #8*8\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        return F.log_softmax(x)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def gray_loader(path):\n",
    "    im=cv2.imread(path,cv2.CV_LOAD_IMAGE_GRAYSCALE)\n",
    "    return  im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "TRAINDIR='/home/wang/git/nppic/ann/train'\n",
    "VALIDATEDIR='/home/wang/git/nppic/ann/val'\n",
    "#73.9896738689 13392.8949973\n",
    "data_transform=transforms.Compose([transforms.ToTensor(),\n",
    "                              transforms.Normalize((73.9896 ,), (13392.8949,)),\n",
    "                             ])\n",
    "trainset = datasets.ImageFolder(root=TRAINDIR, \n",
    "                             transform=data_transform,loader=gray_loader)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=10,shuffle=True, num_workers=1)\n",
    "net=Net()\n",
    "criterion = nn.CrossEntropyLoss() # use a Classification Cross-Entropy loss\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [0/12565 (0%)]\tLoss: 3.526878\n",
      "Train Epoch: 0 [1000/12565 (40%)]\tLoss: 2.805736\n",
      "Train Epoch: 0 [2000/12565 (80%)]\tLoss: 0.769635\n",
      "Train Epoch: 1 [0/12565 (0%)]\tLoss: 1.507317\n",
      "Train Epoch: 1 [1000/12565 (40%)]\tLoss: 0.669195\n",
      "Train Epoch: 1 [2000/12565 (80%)]\tLoss: 0.303886\n",
      "Train Epoch: 2 [0/12565 (0%)]\tLoss: 1.098296\n",
      "Train Epoch: 2 [1000/12565 (40%)]\tLoss: 0.276625\n",
      "Train Epoch: 2 [2000/12565 (80%)]\tLoss: 0.438980\n",
      "Train Epoch: 3 [0/12565 (0%)]\tLoss: 0.276811\n",
      "Train Epoch: 3 [1000/12565 (40%)]\tLoss: 1.073763\n",
      "Train Epoch: 3 [2000/12565 (80%)]\tLoss: 0.444083\n",
      "Train Epoch: 4 [0/12565 (0%)]\tLoss: 0.231498\n",
      "Train Epoch: 4 [1000/12565 (40%)]\tLoss: 0.198737\n",
      "Train Epoch: 4 [2000/12565 (80%)]\tLoss: 0.537617\n",
      "Train Epoch: 5 [0/12565 (0%)]\tLoss: 0.076261\n",
      "Train Epoch: 5 [1000/12565 (40%)]\tLoss: 0.098568\n",
      "Train Epoch: 5 [2000/12565 (80%)]\tLoss: 0.117362\n",
      "Train Epoch: 6 [0/12565 (0%)]\tLoss: 0.444892\n",
      "Train Epoch: 6 [1000/12565 (40%)]\tLoss: 0.070944\n",
      "Train Epoch: 6 [2000/12565 (80%)]\tLoss: 0.065471\n",
      "Train Epoch: 7 [0/12565 (0%)]\tLoss: 0.225997\n",
      "Train Epoch: 7 [1000/12565 (40%)]\tLoss: 0.125286\n",
      "Train Epoch: 7 [2000/12565 (80%)]\tLoss: 0.345837\n",
      "Train Epoch: 8 [0/12565 (0%)]\tLoss: 0.082109\n",
      "Train Epoch: 8 [1000/12565 (40%)]\tLoss: 0.063657\n",
      "Train Epoch: 8 [2000/12565 (80%)]\tLoss: 0.024477\n",
      "Train Epoch: 9 [0/12565 (0%)]\tLoss: 0.008371\n",
      "Train Epoch: 9 [1000/12565 (40%)]\tLoss: 0.024974\n",
      "Train Epoch: 9 [2000/12565 (80%)]\tLoss: 0.126966\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(10): # loop over the dataset multiple times\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader):\n",
    "        inputs, labels = data\n",
    "        inputs=torch.unsqueeze(inputs,1)\n",
    "        # wrap them in Variable\n",
    "        inputs, labels = Variable(inputs), Variable(labels)\n",
    "        #inputs, labels = Variable(inputs.cuda()), Variable(labels.cuda()) #cuda\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # print statistics\n",
    "        running_loss += loss.data[0]\n",
    "        if i % 500 == 0: \n",
    "            #print('[%d, %5d] loss: %.3f' % (epoch+1, i, running_loss / 2000))\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, i * len(data), len(trainloader.dataset),\n",
    "                100. * i / len(trainloader), loss.data[0]))\n",
    "    #print ('Train Epoch: {} total running_loss: {}'.format(epoch,running_loss))\n",
    "    running_loss = 0.0\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "torch.save(net.state_dict(),'/home/wang/git/anpr/coder.net.weight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "以下是验证/测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "model=Net()\n",
    "model.load_state_dict(torch.load('/home/wang/git/anpr/coder.net.weight'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cnt: 610, correct: 571, ratio: 0.00%\n",
      "over\n"
     ]
    }
   ],
   "source": [
    "#SRCDIR='/home/wang/git/nppic/ann/val'\n",
    "#cat,idx=find_classes(SRCDIR)\n",
    "valset = datasets.ImageFolder(root=VALIDATEDIR,\n",
    "                             transform=data_transform,loader=gray_loader)\n",
    "valoader = torch.utils.data.DataLoader(valset, batch_size=10, shuffle=True, num_workers=1)\n",
    "\n",
    "cnt=0\n",
    "correct=0\n",
    "for data in valoader:\n",
    "    images, labels = data\n",
    "    images=torch.unsqueeze(images,1)\n",
    "    outputs = model(Variable(images))\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    c = (predicted == labels).squeeze()\n",
    "    cnt+=len(c)\n",
    "    correct+=torch.sum(c)\n",
    "\n",
    "print \"cnt: {}, correct: {}, ratio: {:.2f}%\".format(cnt,correct,correct/cnt*100.)\n",
    "print 'over'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "以下是工具函数\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over\n"
     ]
    }
   ],
   "source": [
    "#easypy的jpg原图，二值化后，写入bmp，原jpg图像删除\n",
    "#trian，为二值化后的图像. 二值bmp图像写入文件，再读取\n",
    "SRCDIR='/home/wang/git/nppic/ann/train'\n",
    "for root,dirnames,filenames in os.walk(SRCDIR):\n",
    "    if len(filenames)==0:\n",
    "        continue\n",
    "    for i,fname in enumerate(filenames):\n",
    "        source=os.path.join(root,fname)\n",
    "        im=cv2.imread(source,cv2.CV_LOAD_IMAGE_GRAYSCALE)\n",
    "        im=cv2.resize(im,(28,28))\n",
    "        _,timg  = cv2.threshold(im, 100, 255, cv2.THRESH_BINARY)                \n",
    "        #os.unlink(source)\n",
    "        a=source.split('.')\n",
    "        source='{}.bmp'.format(a[0])\n",
    "        #cv2.imwrite(source,timg)\n",
    "print('over')        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over\n"
     ]
    }
   ],
   "source": [
    "#bmp图像扩大三倍，20*20-->60*60\n",
    "SRCDIR='/home/wang/git/nppic/ann/train'\n",
    "#SRCDIR='/home/wang/git/nppic/ann/val'\n",
    "#SRCDIR='/home/wang/git/nppic/ann/mean'\n",
    "for root,dirnames,filenames in os.walk(SRCDIR):\n",
    "    if len(filenames)==0:\n",
    "        continue\n",
    "    for i,fname in enumerate(filenames):\n",
    "        source=os.path.join(root,fname)\n",
    "        im=cv2.imread(source,cv2.CV_LOAD_IMAGE_GRAYSCALE)\n",
    "        im=cv2.resize(im,(60,60))\n",
    "        #cv2.imwrite(source,im)\n",
    "        \n",
    "print('over')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#train 目录所有复制到mean目录\n",
    "SRCDIR='/home/wang/git/nppic/ann/train'\n",
    "DSTDIR='/home/wang/git/nppic/ann/mean/'\n",
    "for root,dirnames,filenames in os.walk(SRCDIR):\n",
    "    if len(filenames)==0:\n",
    "        continue\n",
    "    for i,fname in enumerate(filenames):\n",
    "        source=os.path.join(root,fname)\n",
    "        #shutil.copy(source,DSTDIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73.9896738689 13392.8949973\n"
     ]
    }
   ],
   "source": [
    "#计算mean目录下文件的mean和varience\n",
    "DSTDIR='/home/wang/git/nppic/ann/mean'\n",
    "for root,dirnames,filenames in os.walk(DSTDIR):\n",
    "    ret=np.ndarray((len(filenames),28,28),np.uint8)\n",
    "    for i,fname in enumerate(filenames):\n",
    "        filename=os.path.join(root,fname)\n",
    "        img=cv2.imread(filename,cv2.CV_LOAD_IMAGE_GRAYSCALE)\n",
    "        ret[i]=img\n",
    "#ret=ret\n",
    "mean=np.mean(ret) \n",
    "var=np.var(ret)\n",
    "print mean,var\n",
    "#mean:std:72.2949871181 114.928919566    \n",
    "#mean:var:72.2949871181 13208.6565527   0.283509753404 0.203131973129"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over\n"
     ]
    }
   ],
   "source": [
    "#从train各子目录移动若干文件到val，同时建立对应的子目录\n",
    "SRCDIR='/home/wang/git/nppic/ann/train'\n",
    "DSTDIR='/home/wang/git/nppic/ann/val'\n",
    "for root,dirnames,filenames in os.walk(SRCDIR):\n",
    "    if len(filenames)==0:\n",
    "        continue\n",
    "    d=os.path.join(DSTDIR,os.path.split(root)[1])\n",
    "    #os.mkdir(d)\n",
    "    num=len(filenames)//20\n",
    "    if num<2:\n",
    "        continue\n",
    "    for i in range(num-1):\n",
    "        srcfilename=os.path.join(root,filenames[i])\n",
    "        #shutil.move(srcfilename,d)\n",
    "print('over')        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class NUMPSET(torch.utils.data.Dataset):\n",
    "    picroot='np'\n",
    "\n",
    "    def __getitem__(self,index):\n",
    "        label,img=self.labels[index], self.dataset[index]\n",
    "        if self.data_transform is not None:\n",
    "            img=self.data_transform(img)\n",
    "        #return (img,dirname_to_class(label))\n",
    "        return img,label\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "    def __init__(self,root,data_transform=None):\n",
    "        self.picroot=root\n",
    "        self.data_transform=data_transform\n",
    "\n",
    "        if not os.path.exists(self.picroot):\n",
    "            raise RuntimeError('{} doesnot exists'.format(self.picroot))\n",
    "        for root,dnames,filenames in os.walk(self.picroot):\n",
    "            imgs=[]\n",
    "            labels=[]\n",
    "            for filename in filenames:\n",
    "                picfilename=os.path.join(self.picroot,filename)  #file name:\n",
    "                im=cv2.imread(picfilename,cv2.IMREAD_GRAYSCALE)\n",
    "                _,timg  = cv2.threshold(im, 100, 255, cv2.THRESH_BINARY)                \n",
    "                imgs.append(cv2.resize(timg,(20,20)))  #二值化\n",
    "                m=filename.split('_')  #filename style: x_yyyy.jpg  x is directory and class name\n",
    "                labels.append(m[0])\n",
    "            self.dataset=imgs\n",
    "            self.labels=labels\n",
    "            self.len=len(filenames)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
