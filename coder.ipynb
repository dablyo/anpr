{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "牌照号码训练，数据集使用EasyPR的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path\n",
    "import shutil\n",
    "import cv2\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch.utils.data\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DIGITS='01234567890'\n",
    "LETTER='ABCDEFGHJKLMNPQRSTUVWXYZ'\n",
    "PROV='川鄂赣甘贵桂黑沪冀津京吉辽鲁蒙闽宁青琼陕苏晋皖湘新豫渝粤云藏浙'\n",
    "CHAR=DIGITS+LETTER+PROV\n",
    "CLASSES=['0','1','2','3','4','5','6','7','8','9','0','A','B','C','D','E','F','G','H','J','K','L','M','N','P','Q','R','S','T','U','V','W','X','Y','Z',\n",
    "         'zh_cuan','zh_e','zh_gan','zh_gan1','zh_gui','zh_gui1','zh_hei','zh_hu','zh_ji','zh_jin','zh_jing','zh_jl','zh_liao','zh_lu','zh_meng',\n",
    "        'zh_min','zh_ning','zh_qing','zh_qiong','zh_shan','zh_su','zh_sx','zh_wan','zh_xiang','zh_xin','zh_yu','zh_yu1','zh_yue','zh_yun',\n",
    "        'zh_zang','zh_zhe']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dirname_to_class(cname):\n",
    "    return CLASSES.index(cname)\n",
    "\n",
    "def find_classes(dir):\n",
    "    classes = [d for d in os.listdir(dir) if os.path.isdir(os.path.join(dir, d))]\n",
    "    classes.sort()\n",
    "    class_to_idx = {classes[i]: i for i in range(len(classes))}\n",
    "    return classes, class_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=3,padding=1)   \n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=3,padding=1) \n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(500, 100)\n",
    "        self.fc2 = nn.Linear(100, 65)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))                                #20*20\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))   #10*10\n",
    "        x = x.view(-1, 500)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x)    \n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)                            #28*28\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 100)\n",
    "        self.fc2 = nn.Linear(100, 65)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x)        \n",
    "    \n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class NUMPSET(torch.utils.data.Dataset):\n",
    "    picroot='np'\n",
    "\n",
    "    def __getitem__(self,index):\n",
    "        label,img=self.labels[index], self.dataset[index]\n",
    "        if self.data_transform is not None:\n",
    "            img=self.data_transform(img)\n",
    "        #return (img,dirname_to_class(label))\n",
    "        return img,label\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "    def __init__(self,root,data_transform=None):\n",
    "        self.picroot=root\n",
    "        self.data_transform=data_transform\n",
    "\n",
    "        if not os.path.exists(self.picroot):\n",
    "            raise RuntimeError('{} doesnot exists'.format(self.picroot))\n",
    "        for root,dnames,filenames in os.walk(self.picroot):\n",
    "            imgs=[]\n",
    "            labels=[]\n",
    "            for filename in filenames:\n",
    "                picfilename=os.path.join(self.picroot,filename)  #file name:\n",
    "                im=cv2.imread(picfilename,cv2.IMREAD_GRAYSCALE)\n",
    "                _,timg  = cv2.threshold(im, 100, 255, cv2.THRESH_BINARY)                \n",
    "                imgs.append(cv2.resize(timg,(20,20))/255)  #二值化\n",
    "                m=filename.split('_')  #filename style: x_yyyy.jpg  x is directory and class name\n",
    "                labels.append(m[0])\n",
    "            self.dataset=imgs\n",
    "            self.labels=labels\n",
    "            self.len=len(filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gray_loader(path):\n",
    "    im=cv2.imread(path,cv2.CV_LOAD_IMAGE_GRAYSCALE)\n",
    "    return  (im/255)\n",
    "    #im=cv2.imread(path,cv2.CV_LOAD_IMAGE_GRAYSCALE)\n",
    "    #return cv2.resize(im,(28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "TRAINDIR='/home/wang/git/nppic/ann/train'\n",
    "VALIDATEDIR='/home/wang/git/nppic/ann/val'\n",
    "#先/255，然后mean:0.117357851812 var: 0.321846215497\n",
    "data_transform=transforms.Compose([transforms.ToTensor(),\n",
    "                              transforms.Normalize((0.117357851812,), (0.321846215497,)),\n",
    "                             ])\n",
    "trainset = datasets.ImageFolder(root=TRAINDIR, \n",
    "                             transform=data_transform,loader=gray_loader)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=10,shuffle=True, num_workers=1)\n",
    "net=Model()\n",
    "#net=Net()\n",
    "criterion = nn.CrossEntropyLoss() # use a Classification Cross-Entropy loss\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [0/15435 (0%)]\tLoss: 4.192676\n",
      "Train Epoch: 0 [1000/15435 (32%)]\tLoss: 3.895309\n",
      "Train Epoch: 0 [2000/15435 (65%)]\tLoss: 3.923641\n",
      "Train Epoch: 0 [3000/15435 (97%)]\tLoss: 3.334074\n",
      "Train Epoch: 1 [0/15435 (0%)]\tLoss: 3.496895\n",
      "Train Epoch: 1 [1000/15435 (32%)]\tLoss: 4.042329\n",
      "Train Epoch: 1 [2000/15435 (65%)]\tLoss: 3.178220\n",
      "Train Epoch: 1 [3000/15435 (97%)]\tLoss: 2.934440\n",
      "Train Epoch: 2 [0/15435 (0%)]\tLoss: 3.487466\n",
      "Train Epoch: 2 [1000/15435 (32%)]\tLoss: 3.793392\n",
      "Train Epoch: 2 [2000/15435 (65%)]\tLoss: 3.909380\n",
      "Train Epoch: 2 [3000/15435 (97%)]\tLoss: 3.331851\n",
      "Train Epoch: 3 [0/15435 (0%)]\tLoss: 3.793253\n",
      "Train Epoch: 3 [1000/15435 (32%)]\tLoss: 3.955624\n",
      "Train Epoch: 3 [2000/15435 (65%)]\tLoss: 3.757571\n",
      "Train Epoch: 3 [3000/15435 (97%)]\tLoss: 3.628445\n",
      "Train Epoch: 4 [0/15435 (0%)]\tLoss: 3.966165\n",
      "Train Epoch: 4 [1000/15435 (32%)]\tLoss: 3.659416\n",
      "Train Epoch: 4 [2000/15435 (65%)]\tLoss: 3.548517\n",
      "Train Epoch: 4 [3000/15435 (97%)]\tLoss: 3.525316\n",
      "Train Epoch: 5 [0/15435 (0%)]\tLoss: 3.624390\n",
      "Train Epoch: 5 [1000/15435 (32%)]\tLoss: 2.950113\n",
      "Train Epoch: 5 [2000/15435 (65%)]\tLoss: 3.914120\n",
      "Train Epoch: 5 [3000/15435 (97%)]\tLoss: 3.681372\n",
      "Train Epoch: 6 [0/15435 (0%)]\tLoss: 4.110382\n",
      "Train Epoch: 6 [1000/15435 (32%)]\tLoss: 4.200061\n",
      "Train Epoch: 6 [2000/15435 (65%)]\tLoss: 3.965627\n",
      "Train Epoch: 6 [3000/15435 (97%)]\tLoss: 3.736727\n",
      "Train Epoch: 7 [0/15435 (0%)]\tLoss: 3.937398\n",
      "Train Epoch: 7 [1000/15435 (32%)]\tLoss: 4.065025\n",
      "Train Epoch: 7 [2000/15435 (65%)]\tLoss: 3.477285\n",
      "Train Epoch: 7 [3000/15435 (97%)]\tLoss: 3.379031\n",
      "Train Epoch: 8 [0/15435 (0%)]\tLoss: 4.136447\n",
      "Train Epoch: 8 [1000/15435 (32%)]\tLoss: 3.777892\n",
      "Train Epoch: 8 [2000/15435 (65%)]\tLoss: 3.837805\n",
      "Train Epoch: 8 [3000/15435 (97%)]\tLoss: 4.042259\n",
      "Train Epoch: 9 [0/15435 (0%)]\tLoss: 3.863878\n",
      "Train Epoch: 9 [1000/15435 (32%)]\tLoss: 4.195497\n",
      "Train Epoch: 9 [2000/15435 (65%)]\tLoss: 4.674917\n",
      "Train Epoch: 9 [3000/15435 (97%)]\tLoss: 4.137120\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(10): # loop over the dataset multiple times\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader):\n",
    "        inputs, labels = data\n",
    "        inputs=torch.unsqueeze(inputs,1)\n",
    "        # wrap them in Variable\n",
    "        inputs, labels = Variable(inputs), Variable(labels)\n",
    "        #inputs, labels = Variable(inputs.cuda()), Variable(labels.cuda()) #cuda\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.data[0]\n",
    "        if i % 500 == 0: \n",
    "            #print('[%d, %5d] loss: %.3f' % (epoch+1, i, running_loss / 2000))\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, i * len(data), len(trainloader.dataset),\n",
    "                100. * i / len(trainloader), loss.data[0]))\n",
    "    #print ('Train Epoch: {} total running_loss: {}'.format(epoch,running_loss))\n",
    "    running_loss = 0.0\n",
    "print('Finished Training')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "torch.save(net.state_dict(),'/home/wang/git/anpr/coder.model.weight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以下是验证/测试，部分工具函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#model=Net()\n",
    "model=Model()\n",
    "model.load_state_dict(torch.load('/home/wang/git/anpr/coder.model.weight'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cnt: 716, correct: 646, ratio: 0.00%\n",
      "over\n"
     ]
    }
   ],
   "source": [
    "#SRCDIR='/home/wang/git/nppic/ann/val'\n",
    "#cat,idx=find_classes(SRCDIR)\n",
    "valset = datasets.ImageFolder(root=VALIDATEDIR,\n",
    "                             transform=data_transform,loader=gray_loader)\n",
    "valoader = torch.utils.data.DataLoader(valset, batch_size=10, shuffle=True, num_workers=1)\n",
    "\n",
    "cnt=0\n",
    "correct=0\n",
    "for data in valoader:\n",
    "    images, labels = data\n",
    "    images=torch.unsqueeze(images,1)\n",
    "    outputs = model(Variable(images))\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    c = (predicted == labels).squeeze()\n",
    "    cnt+=len(c)\n",
    "    correct+=torch.sum(c)\n",
    "\n",
    "print \"cnt: {}, correct: {}, ratio: {:.2f}%\".format(cnt,correct,correct/cnt*100)\n",
    "print 'over'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "over\n"
     ]
    }
   ],
   "source": [
    "#train-src为原图像\n",
    "#trian，为二值化后的图像. 二值jpg图像写入文件，再读取\n",
    "SRCDIR='/home/wang/git/nppic/ann/train'\n",
    "for root,dirnames,filenames in os.walk(SRCDIR):\n",
    "    if len(filenames)==0:\n",
    "        continue\n",
    "    for i,fname in enumerate(filenames):\n",
    "        source=os.path.join(root,fname)\n",
    "        im=cv2.imread(source,cv2.CV_LOAD_IMAGE_GRAYSCALE)\n",
    "        _,timg  = cv2.threshold(im, 100, 255, cv2.THRESH_BINARY)                \n",
    "        a=source.split('.')\n",
    "        source='{}.bmp'.format(a[0])\n",
    "        cv2.imwrite(source,timg)\n",
    "print('over')        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#train 目录所有jpg复制到mean目录\n",
    "SRCDIR='/home/wang/git/nppic/ann/train'\n",
    "DSTDIR='/home/wang/git/nppic/ann/mean/'\n",
    "for root,dirnames,filenames in os.walk(SRCDIR):\n",
    "    if len(filenames)==0:\n",
    "        continue\n",
    "    for i,fname in enumerate(filenames):\n",
    "        source=os.path.join(root,fname)\n",
    "        shutil.copy(source,DSTDIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.117357851812 0.321846215497\n"
     ]
    }
   ],
   "source": [
    "#计算mean目录下文件的mean和varience\n",
    "DSTDIR='/home/wang/git/nppic/ann/mean'\n",
    "for root,dirnames,filenames in os.walk(DSTDIR):\n",
    "    ret=np.ndarray((len(filenames),20,20),np.uint8)\n",
    "    for i,fname in enumerate(filenames):\n",
    "        filename=os.path.join(root,fname)\n",
    "        img=cv2.imread(filename,cv2.CV_LOAD_IMAGE_GRAYSCALE)\n",
    "        ret[i]=img\n",
    "ret=ret/255        \n",
    "mean=np.mean(ret) \n",
    "var=np.std(ret)\n",
    "print mean,var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#从train各子目录移动若干文件到val，同时建立对应的子目录\n",
    "SRCDIR='/home/wang/git/nppic/ann/train'\n",
    "DSTDIR='/home/wang/git/nppic/ann/val'\n",
    "for root,dirnames,filenames in os.walk(SRCDIR):\n",
    "    if len(filenames)==0:\n",
    "        continue\n",
    "    d=os.path.join(DSTDIR,os.path.split(root)[1])\n",
    "    os.mkdir(d)\n",
    "    num=len(filenames)//20\n",
    "    if num==0:\n",
    "        continue\n",
    "    for i in range(num-1):\n",
    "        srcfilename=os.path.join(root,filenames[i])\n",
    "        shutil.move(srcfilename,d)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
